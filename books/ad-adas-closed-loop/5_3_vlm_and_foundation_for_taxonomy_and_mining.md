---
title: "5.3 VLM / Foundation Model を用いた環境タクソノミ・シナリオマイニング"
---

# 5.3 VLM / Foundation Model を用いた環境タクソノミ・シナリオマイニング

この節では、Vision-Language Model (VLM) や Foundation Model を用いた環境タクソノミ構築とシナリオマイニングについて解説します。ログからのシーン自動要約・タグ付け、潜在シナリオの抽出、ラベル定義の再設計への活用を整理し、データ中心・Closed-Loop の観点から「ラベルスキーマ自体をモデルと共進化させる」考え方を紹介します。

## シーン自動要約・タグ付け

VLM を用いることで、画像やシーンから自然言語による要約やタグを自動生成し、人手ラベルの補助として利用することができます。例えば、「雨の夜に交差点で歩行者が横断している」といった説明を自動生成し、それをシナリオタグ候補としてカタログに登録する、といった使い方です。

## 潜在シナリオの抽出とラベル定義の再設計

VLM や自己教師ありモデルから得られる埋め込み空間をクラスタリングし、人間が事前に想定していなかったシナリオクラスターを発見することも可能です。Closed-Loop の観点では、こうした潜在シナリオをきっかけにタクソノミを見直し、新たなラベル定義を追加することで、モデルが扱う世界の解像度を高めていくアプローチが考えられます。

## テキストクエリベースのシーン検索

近年の CLIP 系モデルや Vision-Language Foundation Model は、テキストと画像・動画を同一の埋め込み空間 (joint embedding space) にマップする能力を持ちます。これを利用すると、次のようなテキストクエリベースのシーン検索 (text-based scene retrieval) が実現できます。

- 「雨の夜の交差点で、歩行者が赤信号で横断しているシーン」
- 「高速道路で合流してくるトラックの直前に急ブレーキしたケース」
- 「工事区間でコーンが倒れているレーンチェンジ」

具体的には、すべてのフレーム／短いクリップに対して VLM 由来の埋め込みを事前計算し、ベクトルデータベース (vector database) に格納しておきます。その上で、ユーザーの自然言語クエリを埋め込みに変換し、コサイン類似度などで最近傍検索を行います。

この仕組みをラベリングプロセスに統合すると、

- 「○○という事故レポートに似た状況のシーンを大量に抽出し、ラベル付けする」
- 「特定の交通ルール違反が疑われるシーンだけを集中的にレビューする」

といった、シナリオ駆動のデータ選択が容易になります。第4章で述べたシーン検索基盤と合わせて、VLM ベースの検索は Closed-Loop における「問題シーンの特定 → ラベル付け → モデル改善」の入口として有効です。

## 埋め込み空間のクラスタリングとシナリオマイニング

VLM や自己教師ありモデルから得られた埋め込み空間には、人間が明示的に定義していないシナリオの構造が潜んでいることが多いです。例えば、

- 「夜間・雨天・対向車ヘッドライトあり・標識が見えづらい」シーンのクラスタ
- 「住宅街で子供が遊んでいる・ボールが飛び出してくる」シーンのクラスタ
- 「交差点で右折車と横断歩道の歩行者がせめぎ合っている」シーンのクラスタ

などが、クラスタリング (clustering) や次元削減可視化 (t-SNE, UMAP など) により浮かび上がってきます。

シナリオマイニングの典型的なプロセスは次の通りです。

1. **埋め込み算出**  
   画像・動画・マルチカメラビューを VLM・自己教師ありモデルに入力し、シーンレベルの埋め込みベクトルを得ます。必要に応じて、LiDAR 特徴量や地図特徴量も連結します。
2. **クラスタリング**  
   k-means、DBSCAN、階層クラスタリングなどを用いて埋め込み空間をクラスタリングします。クラスタ数は事前に固定する方法もあれば、密度ベース手法で自動決定する方法もあります。
3. **代表シーンのレビュー**  
   各クラスタから代表フレームを抽出し、人間のエキスパートが意味づけ（「渋滞末尾」「高速道路合流の急減速」「工事区間での車線変更」など）を行います。
4. **タクソノミへの反映**  
   意味のあるクラスタに対して新しいシナリオタグを追加し、ラベルポリシーに取り込みます。同時に、ラベリングツールやデータカタログに新タグを反映します。

このように、タクソノミをトップダウンに設計するだけでなく、VLM・自己教師ありモデルからのボトムアップなシナリオ発見を組み合わせることで、データ中心の設計が可能になります。

## VLM を用いる際の注意点と Closed-Loop 連携

VLM は非常に強力ですが、ドメインギャップ (domain gap) や幻覚 (hallucination) に注意する必要があります。インターネット画像で学習された汎用モデルは、車載カメラの歪みや夜間・悪天候の映像に対して誤った説明を生成することがあり、自動運転向けのタスクでは次のような配慮が必要です。

- まずは VLM が提案したタグやシナリオ名を「候補」として扱い、人間のレビューを必須とする。
- 重要な安全クリティカルシナリオ（歩行者飛び出し、緊急車両接近など）については、VLM に過度に依存せず、従来のルールベース検知や専用モデルとの併用を行う。
- 説明テキストそのものをラベルとして保存する場合、プライバシー情報（ナンバープレート・具体的な地名など）が含まれないようフィルタリングする。

Closed-Loop の観点では、VLM を「データ探索とタクソノミ改善のためのツール」と位置づけます。すなわち、

- オンライン評価や実路試験で発生したエラーシーン周辺を VLM で検索・拡張し、類似シーンを大量に抽出する。
- 抽出したシーンに対して新しいシナリオタグやラベル定義を追加し、再学習・再評価のループを回す。

という形で、VLM を Closed-Loop データエンジンの一構成要素として活用します。このとき、VLM 自体のバージョンやプロンプト設計も、ラベルポリシーと同様に管理・記録しておくことが重要です。

## 5.3.1 自動運転向け VLM / Foundation Model 研究の俯瞰

この節では、近年提案されている自動運転向け Vision-Language Model (VLM) / Vision-Language-Action Model (VLA) / Foundation Model の代表的な研究を俯瞰し、それぞれの手法がどのように環境タクソノミ・シナリオマイニング・ラベリングに寄与しうるかを整理します。具体的には、DriveLM、DriveBench / Are VLMs Ready for Autonomous Driving?、STRIDE-QA、Talk2BEV、EMMA、SimLingo、DriveGPT、Poutine、ReCogDrive、DriveAction、DiMA などの手法を取り上げます。

ここで扱う論文群は、VLM / Foundation Model をデータエンジンそのものの中に組み込もうとする潮流を代表していると考えられます。単に perception モデルを高性能化するだけでなく、シナリオ定義・ラベル設計・評価・フィードバックまでを包括的に扱う点が重要です。

以下では、タスクの性質ごとにグルーピングしながら各手法を見ていき、最後にこれらをデータ中心・Closed-Loop 観点からどのように統合していくかを考察します。

### Driving VQA と知識グラフ：DriveLM (G-VQA; 2312.14150)

DriveLM は、自動運転シーンを対象とした Graph Visual Question Answering (G-VQA) ベンチマークおよびモデルです。カメラ画像や周辺オブジェクト、車線、信号、マップ情報などをグラフ構造で表現し、その上で「質問 (question) — 答え (answer) — 根拠 (rationale)」の形式でマルチレベルなタスクを定義します。質問は、(1) 認識系（例: 「横断歩道上に歩行者はいるか」）、(2) 予測系（例: 「前方車両は次に何をしそうか」）、(3) 計画系（例: 「安全に進むべきレーンはどれか」）、(4) 説明系（例: 「なぜ減速すべきか」）など、運転意思決定の階層構造を網羅するように設計されています。

G-VQA の枠組みでは、ピクセルレベルのラベル（バウンディングボックスやセマンティックマスク）だけでなく、「どのオブジェクトがどの交通ルールに関わっているか」「どの関係が危険度を高めているか」といった関係ラベル・イベントラベルが多く含まれます。これは、従来のオブジェクト中心タクソノミから一歩進んで、「シーン内の関係・因果構造」をタクソノミの一級市民として扱うアプローチと解釈できます。

実務への示唆として、DriveLM のような G-VQA ベンチマークは次のような用途に応用しやすいです。

- **タクソノミ設計のテンプレート化**: 「どのような質問カテゴリを用意すると、運転システムの理解と評価がしやすいか」を具体的な QA テンプレートとして提示してくれます。社内タクソノミ設計時に、DriveLM の質問カテゴリを参考にして自社版 QA テンプレートを作ることで、評価やシナリオマイニングが行いやすくなります。
- **シーンレベル・シナリオレベルのラベルスキーマ**: QA そのものを「シナリオラベル」とみなし、「この質問に Yes が返るシーン集合」「No が返るシーン集合」としてシーンを切り分けることができます。これにより、「信号無視が起きているシーン」「右折時に歩行者とのコンフリクトがあるシーン」のような高レベルラベルを効率的に構築できます。
- **Closed-Loop 評価との接続**: QA ベースでモデルを評価することで、「どの種類の質問（=どのタクソノミ要素）でエラーが多いか」が明確になります。その結果を第 4 章・第 6 章のデータ選択・トレーニングにフィードバックすることで、「特定の QA カテゴリに対応するシーンを重点的に追加収集・再ラベリングする」といった Closed-Loop が構成しやすくなります。

DriveLM のデータセット構築プロセスの観点から見ると、まず nuScenes や Argoverse などの既存データセットの「オブジェクト・レーン・信号・マップ」情報を統合し、シーンごとのグラフ表現を生成しています。その際、単にオブジェクトの存在やクラスだけでなく、「どの車両がどのレーンに属しているか」「どの歩行者がどの横断歩道と関連しているか」「どの信号がどの車線に対して効力を持つか」といった **関係ラベル (relation label)** を体系的に定義する必要があります。これは、従来はラベリングガイドラインの脚注レベルに埋もれがちであった関係情報を、一段階引き上げて「ラベルスキーマのコア要素」として再定義していると捉えられます。

また、DriveLM は質問テンプレートを用いて大量の QA ペアを自動生成しつつ、一部の難しい質問については人間のアノテータによる検証・修正を行っています。このとき、「テンプレートから生成できる QA」と「生成が難しく、人手設計が必要な QA」の境界が浮き彫りになります。たとえば、単純な存在確認や距離比較はテンプレート生成しやすい一方で、「なぜその行動が危険か」「別の安全な行動案は何か」といった説明・代替案を問う質問は、LLM や人間の知識に強く依存します。実務では、この境界を参考にしながら「どこまでをルールベースな QA 生成に任せ、どこからをエキスパートレビューに回すか」を設計するとよいです。

モデルアーキテクチャの観点では、DriveLM はシーンのグラフ表現をエンコードする Graph Neural Network (GNN) と、自然言語処理を担う LLM を組み合わせた構成を採用しています。単に画像特徴を LLM に渡すのではなく、「ノード（オブジェクト・レーン・信号）」「エッジ（関係）」を明示的に LLM へ渡すことで、**どのエッジがどの回答に効いているか** をある程度トレース可能にしています。これは、「エラー時にどの関係ラベルが間違っていたのか」を追いやすくするという意味で、データ中心・Closed-Loop な改善サイクルと整合的です。

DriveLM の実験結果からは、汎用 VLM をそのまま利用した場合に比べて、グラフ構造を明示的に扱うアプローチのほうが、複雑な関係推論や multi-hop reasoning において優れていることが示されています。一方で、元となるデータセットの地理的・シナリオ的な多様性には限りがあり、雪道や右側通行・左側通行の違い、ローカルな交通文化などは十分にカバーされていない可能性があります。実務で DriveLM 的な枠組みを導入する場合、自社フリートの ODD に合わせて **ローカルルール・ローカルシナリオを含む拡張版グラフタクソノミ** を設計しなおす必要がある点に注意が必要です。

まとめると、DriveLM は「ピクセル → オブジェクト → 関係 → 質問」という階層構造を通じて、環境タクソノミをかなり明示的な形に押し出した研究である、と位置づけられます。本書で扱うデータ中心・Closed-Loop 開発の観点からは、DriveLM のような G-VQA ベンチマークを **社内版の「運転知識テスト」** として構築し、モデル・データセット・ラベリングポリシーの改善サイクルの指標にする、という発想が非常に重要になります。

### 信頼性評価と QA データセット：Are VLMs Ready for Autonomous Driving? / DriveBench (2501.04003) と STRIDE-QA

「Are VLMs Ready for Autonomous Driving?」は、汎用 VLM が自動運転の文脈でどの程度信頼できるかを、専用の QA ベンチマーク DriveBench を用いて体系的に評価した研究です。代表的なオープンソース VLM / 商用 VLM を複数選び、 perception・prediction・planning・リスク評価など、多段階の問いに対する正答率・一貫性・ロバストネスを分析しています。その結果として、現時点の VLM は人間レベルからはまだ大きく乖離しており、とくに安全クリティカルな問いや長尾シナリオに対しては信頼できないことが多い、という慎重な結論を提示します。

DriveBench と密接に関連する取り組みとして、STRIDE-QA のような大規模 QA データセットがあります。STRIDE-QA は、実世界・シミュレーションの走行ログから数百万フレーム・数千万クラスの QA ペアを構成し、物体認識・車線理解・オブジェクト間関係・将来予測・リスク評価・運転方針など、多数のサブタスクを自然言語 QA という共通フォーマットに埋め込んでいます。多くの QA はルールベースや既存ラベルから半自動的に生成され、一部は LLM による補完やチェックが行われています。

ラベリングとタクソノミの観点から見ると、これらの研究は次のような示唆を与えます。

- **QA を通じたタクソノミの正規化**  
  「どのような質問を用意すると運転性能と安全性をカバーできるか」を明示的に列挙することで、散逸しがちなラベルポリシーを整理する助けになります。STRIDE-QA などの QA テンプレートを参照し、自社 ODD に合わせて質問文・回答スキーマをカスタマイズすることで、ラベルスキーマのギャップを発見しやすくなります。
- **VLM の限界を前提とした運用設計**  
  Are VLMs Ready? の結果は、「VLM は便利だが、現状では人間監督なしに安全クリティカルな判断を完全に任せるべきではない」という前提を与えてくれます。Closed-Loop の設計においても、VLM を「候補シーンのサジェスタ」「タクソノミ改良のヒント提供者」として位置づけ、人間レビューで最終決定するワークフローを崩さないことが重要です。

DriveBench の設計をもう少し詳しく見ると、質問は大きく「静的理解（Static Perception）」「動的理解（Dynamic Perception / Prediction）」「行動・意図推定（Intention / Behavior）」「危険度評価（Risk Assessment）」「ルール・常識（Traffic Rules / Commonsense）」といったカテゴリに分かれています。各カテゴリ内でも、「単一フレームから答えられるもの」と「複数フレームの時系列や地図情報を統合しなければ答えられないもの」が混在しており、VLM がどの情報ソースにどこまで依存しているかを切り分けやすい構造になっています。実験では、画像のみを与えた場合と、画像＋テキストヒント（例: 交通ルールの説明）を与えた場合の性能差なども分析されており、「VLM はルールの明示があると急に強くなるが、ルールが暗黙に含まれるシーンでは弱い」といった傾向が報告されています。
この知見は、シナリオマイニングやラベリングでも重要です。例えば、「赤信号無視」のようなシナリオを抽出したい場合、単に赤信号と進入車両が同時に存在するフレームを探すだけでは不十分であり、「どの信号がどの車線に対応しているか」「その車線に属する車両がどのタイミングで停止線を越えたか」といった関係・時間情報を正しく扱う必要があります。DriveBench の結果を見ると、現状の VLM はこうした *implicit rule grounding* に弱く、きちんとしたタクソノミ・スキーマを用意しないまま VLM だけに頼ってシーン抽出を行うのは危険である、という示唆が得られます。

一方、STRIDE-QA は Turing Motors による、よりスケールに振り切った driving QA データセットです。公開情報によれば、実車ログとシミュレーションログを組み合わせて、2D / 3D perception、マップ・レーンレベル理解、オブジェクト間関係、短期予測、リスク評価、運転方針決定などをカバーする数億規模の QA ペアを構築しており、CoVLA 系の大規模ビデオ・アクションデータと組み合わせて学習・評価に用いています。QA は多段階の自動生成パイプラインと LLM ベースの検証ステージを通じて品質を担保しており、長尾シナリオや安全クリティカルイベントをカバーするためのサンプリング戦略も工夫されています。

STRIDE-QA の興味深い点は、「QA のスキーマ自体を Closed-Loop の中で更新していく」ことを前提にしているところです。サービスの拡大に伴って新しい事故タイプやヒヤリハットが見つかった場合、その事例から新しい QA テンプレートを設計し、過去ログに対して一括適用することで、「新しいシナリオについても全履歴を横断して検索・評価できる」状態を作る、という運用が想定されています。これは、本書で繰り返し述べている「データスキーマ・ラベルスキーマそのものをモデルと同様にバージョン管理し、Closed-Loop に進化させる」という思想と非常に整合的です。

実務的には、DriveBench / STRIDE-QA のような QA スキーマをそのまま採用するのではなく、自社の ODD・サービス仕様・安全要件に合わせてサブセット・拡張を行ったうえで、「QA スキーマ → ラベル定義 → シナリオタグ → シーン検索クエリ」という対応表を作成するとよいです。その対応表を DataOps / MLOps のパイプラインに組み込んでおけば、オンラインで検出されたエラー種別（例: 「追従時車間距離が短すぎる」）から、過去ログ中の類似 QA を満たすシーン集合を即座に引き当て、再ラベリング・再学習の対象にできるようになります。

### BEV / HD マップ条件付きの対話型理解：Talk2BEV (2310.02251)

Talk2BEV は、Bird's-Eye View (BEV) 特徴と HD マップ情報を用いて、自然言語による対話型シーン理解を実現するフレームワークです。従来の画像ベース VLM が「前方カメラ画像 1 枚」に対する説明にとどまりがちであったのに対し、Talk2BEV は複数カメラ・BEV 特徴・マップを統合した中間表現をベースに、「現在の自車位置はどのレーンか」「この先何車線に分岐するか」「右折専用レーンはどこか」といった質問に答えます。

タクソノミ・シナリオマイニング観点では、Talk2BEV が提供するのは「地図・レーン構造に強く結びついた質問テンプレート」です。具体的には次のような応用が考えられます。

- レーンレベル・ジャンクションレベルのシナリオタグ（合流、分岐、車線減少、右折専用など）を自然言語で定義し、Talk2BEV 的なモデルに問い合わせることで、ログから該当シーンを抽出する。
- 「この地点で自車が取れる行動候補は何か」「安全に停止できる場所はどこか」といった、地図制約付きの行動空間を QA で表現し、その結果をタクソノミとしてデータカタログに取り込む。

第 3 章で述べた HD マップ・レーンレベル構造と、第 4 章・第 5 章で扱うシーン検索・ラベリングを橋渡しする役割を担える点が、Talk2BEV 系の手法の大きなポイントです。

Talk2BEV の内部構成をもう少し見ると、まずマルチカメラ画像から既存の BEV ネットワーク（BEVFormer 系など）で鳥瞰表現を構築し、そこに HD マップのレーン・車線境界・交差点構造を重ね合わせた **統一 BEV フィーチャマップ** を作ります。そのうえで、テキストエンコーダで埋め込んだ質問ベクトルをクエリとして扱い、Transformers によって BEV 上の位置・オブジェクト・レーン情報とクロスアテンションさせることで、回答トークンを生成する構成になっています。

この設計により、質問の種類ごとに参照される BEV 領域やマップ要素が異なるため、「どのレーン・どのジャンクション情報が回答に効いているか」を可視化しやすい利点があります。実務的には、Talk2BEV のアテンションマップをそのまま「シナリオの空間的範囲」として利用し、「この質問に対してモデルが重要だと考えたエリア」をシーンタグや難例マイニングの候補としてカタログ化する、といった応用が考えられます。

また、Talk2BEV では質問テンプレートとして、「レーン数」「レーン属性（合流・分岐・専用レーンなど）」「距離・方位」「交差点構造」「ランドマークとの位置関係」などが用意されています。これらはそのまま環境タクソノミの上位概念に対応しており、タクソノミ設計時に「どの属性について質問を投げられる状態にしたいか」を検討する指針になります。たとえば、自社 ODD において高速道路の合流・分岐シナリオが重要であれば、Talk2BEV 型の QA をそのまま「合流タクソノミのチェックリスト」として流用し、データ収集・ラベリング・評価で同じ観点を貫くことができます。

### Embodied マルチモーダルエージェント：EMMA (2410.23262)

EMMA (Embodied Multi-Modal Agent) は、カメラ画像・地図・センサ・テキスト指示などを統合し、人間と対話しながら運転シーンを理解・説明するエージェントアーキテクチャです。LLM と VLM を中核に据えつつ、周辺に perception モジュールやルールエンジンを配置することで、「今なにが起きているか」「なぜその行動を選ぶのか」を自然言語で説明できるよう設計されています。

EMMA 型のエージェントは、次のようなラベリング支援に利用できます。

- エキスパートが EMMA に対して「このシーンはどのような危険要因を含んでいるか」「運転者は何に注意すべきか」などの質問を行い、その回答をもとにシナリオタグ候補を生成する。
- EMMA が生成する説明テキストを、DriveLM や STRIDE-QA のような QA ベンチマークと同じ形式にマッピングし、説明付き QA データとして蓄積する。

Closed-Loop の観点では、実運用中に発生したインシデントについて EMMA に「事後説明」をさせ、その説明ログをもとに新たなタクソノミ要素（例: 「視界不良 + 自転車飛び出し」コンビネーション）を追加する、といったループが考えられます。

論文レベルでは、EMMA は単一モデルではなく複数コンポーネントから成るエージェントとして定義されています。典型的には、(1) センサデータからオブジェクト・レーン等の低レベル情報を抽出する perception モジュール群、(2) それらを統合して抽象的な世界状態を構築する world model、(3) 世界状態を自然言語で説明・計画に変換する LLM ベースの reasoning モジュール、の三層構成を取り、モジュール間は明示的な API で接続されています。

このような分割は、データ中心・Closed-Loop の観点から見ると「どのレベルの表現をラベルとして残し、どのレベルをオンザフライで計算するか」を決める指針を与えてくれます。例えば、perception モジュールの出力（検出ボックスやトラジェクトリ）だけでなく、EMMA 内部で構築される「状況サマリテキスト」や「将来リスクに関する説明文」をログとして保存しておけば、後からそれらをシナリオタグ・QA ラベルとして再利用できます。逆に言えば、そうした中間表現を一切保存していないと、後から「なぜこのシーンでモデルが誤った判断をしたのか」を再構成することが難しくなります。

EMMA の実験では、CARLA のようなシミュレータ環境と実車ログを組み合わせ、対話シナリオ（ユーザからの質問に答えるタスク）やインストラクションフォロー（自然言語で与えた運転指示に従うタスク）を通じてエージェントの能力を評価しています。結果として、人間との対話を通じて「どのシナリオに対する理解が浅いか」「どの危険要因の説明が不十分か」といった弱点が明らかになり、その弱点に対応するデータを追加収集・再ラベリングすることで性能が改善することが示唆されています。現場で EMMA 型のエージェントを導入する場合、「対話ログ＝データ改善のための要求仕様」とみなして、DataOps チームに戻す運用を設計するとよいです。

### シミュレーションと自然言語の橋渡し：SimLingo (2503.09594)

SimLingo は、自然言語による指示から運転シミュレータ内のシーンやシナリオを自動生成・編集するためのフレームワークです。「雨の夜の高速道路合流で、後方から速い車が接近してくるシーンを作成して」「横断歩道を走って渡る歩行者がいるシナリオを 100 パターン生成して」などのテキストプロンプトを受け取り、シミュレータ上のエージェント・交通流・環境条件を設定します。

SimLingo のようなテキスト駆動シミュレーションは、環境タクソノミと非常に相性が良いです。理由は、タクソノミで定義したシナリオ名・属性（天候・時間帯・道路種別・交通量など）をそのままプロンプトに組み込むことで、「特定タクソノミ要素を持つシーンを大量生成する」ことが可能になるためです。

- ラベルポリシーで定義したシナリオタグ（例: `merge_highway_rainy_night`）を SimLingo にそのまま渡して合成シーンを生成し、モデルのロバスト性評価やデータ補完に使う。
- 第 7 章で扱うシナリオベーステストと接続し、「タクソノミ → プロンプト → シミュレーション → Closed-Loop 評価」という一連の流れを自動化する。

このように、SimLingo は「タクソノミを実際に再生できるプログラム表現に落とし込む」ための重要なレイヤとして位置づけられます。

SimLingo の技術的なポイントは、自然言語プロンプトをそのままシミュレータの低レベルパラメータ（車両の初期位置・速度分布・交通流・信号サイクル・天候パラメータなど）に変換するのではなく、一度 **中間のシナリオ表現 (scenario program)** にマッピングするところにあります。論文では、シナリオを「エージェントの役割」「時間軸上のフェーズ」「環境条件」の組み合わせとして形式化し、そのプログラムをさらに具体的なシミュレーション設定へとコンパイルする二段階構成を採用しています。

この構造により、同じシナリオプログラムから複数のバリエーション（例: 車両密度だけを変える、歩行者の初期位置だけを変える）を系統立てて生成できるため、「特定タクソノミ要素を固定したまま他の要素だけをスイープする」といった実験が行いやすくなります。データ中心の観点では、こうしたパラメトリックなシナリオ生成は、データセットの「どの軸が不足しているか」を調べる感度分析にそのまま対応します。

一方で、SimLingo のような生成シミュレーションに過度に依存すると、「現実には存在しないがシミュレーション上は大量に存在する」シナリオが増えすぎるリスクがあります。Closed-Loop の設計では、必ず実ログから抽出した代表的なシーンと SimLingo による合成シーンを比較し、「生成シナリオが現実の分布からどの程度外れているか」をモニタリングする仕組みを用意することが望ましいです。その意味で、SimLingo は第 7 章で扱うシミュレーション評価だけでなく、第 2 章・第 3 章の実世界データ収集・保存フェーズとも密接に結びついた技術だと考えられます。

### 自然言語付きポリシーモデル：DriveGPT (2412.14415)

DriveGPT は、GPT 系の autoregressive モデルを応用し、連続した運転シーンに対して将来の制御トークン（ステアリング・アクセル・ブレーキなど）と自然言語による説明トークンを同時に生成することを目指したモデルです。マルチカメラ画像列やマップ情報をエンコードし、時間方向に沿ってトークン列として処理することで、「次にどのように操作するか」と「なぜそうするのか」を一本の言語モデルで表現しようとします。

DriveGPT のようなモデルは、ラベリング観点では「運転ポリシーに対する自己解説ラベル」を自動で付与する装置として利用できます。たとえば以下のようなループが考えられます。

- 過去ログに対して DriveGPT をオフラインで適用し、各時刻で「推奨行動」と「その理由」のテキストを生成する。
- 人間のエキスパートがテキストをレビューし、「妥当な説明」と「危険な誤解」を仕分けしながら、新しいシナリオタグ（例: 「視界不良を正しく認識して減速したケース」「歩行者を誤認識して不要に減速したケース」）を定義する。

これにより、「行動レベル・意思決定レベルのタクソノミ」をデータ駆動で構築し、評価指標やフィードバックループに組み込むことが可能になります。

DriveGPT の論文では、入力・出力の表現形式をすべてトークン列に統一することで、「テキスト指示」「センサ由来のシンボリック表現（例: オブジェクト ID やレーン ID）」「連続制御量」を一つの言語モデルで扱えるように設計しています。具体的には、ステアリング角や加速度といった連続値を事前に量子化して離散トークンに変換し、時系列方向に沿って `[観測トークン][行動トークン][説明トークン]` のようなシーケンスを構成します。これにより、「行動と説明が一貫しているか」「同じシーンに対して複数の説明候補を生成できるか」といった性質を、言語モデルの枠組みの中で解析できます。

評価実験では、オフライン指標（行動予測精度や説明文の QA スコア）に加えて、シミュレーション内での Closed-Loop 走行評価も行われており、「説明付きポリシー」が純粋な行動ポリシーと比べてどの程度性能を維持できるか、あるいはどの条件で性能が劣化しやすいかが分析されています。興味深い傾向として、説明トークンを併せて生成させることでモデルの学習が正則化され、一部のタスクでは説明なしのモデルよりも行動予測精度が向上するという結果も報告されています。これは、ラベル設計の観点から見ると「行動ラベルだけでなく説明ラベルも同時に集める価値がある」ことを示唆するものです。

実務で DriveGPT 的な枠組みを導入する場合、エキスパートドライバーによるテレオペレーションやシミュレーション走行時に、「操作ログ＋口頭説明」を同時に記録する運用を設計しておくとよいです。説明テキストは完全でなくても構わず、後段で EMMA や VLM を使って補完・要約・ QA 化することができます。こうして得られた「行動＋説明ラベル付きログ」は、タクソノミ設計・行動評価・デバッグ・シナリオマイニングのすべてにとって貴重なリソースになります。

### 自己改善型 Foundation Agent：Poutine (2506.11234)

Poutine は、自動運転向けの Foundation Agent を構築し、シミュレーションやログを通じて自己改善 (self-improvement) を行うことを目指したフレームワークです。VLM / LLM を用いてシーン理解・プラン生成・フィードバック解析を行い、オフラインデータとオンラインシミュレーションを行き来しながらポリシーを継続的に更新します。

Poutine のような自己改善フレームワークが示しているのは、「エラー解析 → データ選択 → 再学習」という Closed-Loop を、Foundation Model を中心に据えてほぼ自動化するビジョンです。具体的には、

- シミュレーションや実ログで失敗したシナリオを自動検出し、そのテキスト説明を生成・クラスタリングして「どのような失敗モードが多いか」を整理する。
- 整理された失敗モードごとに、SimLingo やデータ選択パイプラインを呼び出し、追加データ収集・再ラベリング・再学習をトリガする。

といった一連のループを、エージェント自身がある程度管理・実行する、という方向性です。実務では完全自動化までは難しいことが多いですが、少なくとも「エラーのテキスト要約とシナリオクラスタリング」を自動化することで、データエンジニア・ラベリングチームの負荷削減に寄与しやすいです。

Poutine の提案する自己改善サイクルは、本書で述べる 7 段階 Closed-Loop データエンジンのうち、(V) モデル学習・オフライン評価〜(VII) 実世界展開・フィードバック の部分をほぼ自動で回すことを狙っています。論文では、(1) Foundation Model を用いた初期ポリシーの学習、(2) シミュレーション環境でのロールアウトと失敗ケースの自動収集、(3) 失敗ケースに対するテキスト要約・分類、(4) それぞれの失敗クラスに対するデータ補完・再学習、というループが繰り返し適用されます。

重要なのは、失敗クラスを単に「成功 / 失敗」のような二値ラベルで管理するのではなく、「どの環境タクソノミ要素と結びついた失敗か」（例: 雨天・夜間・合流・視界不良・自転車など）を EMMA や DriveLM 的な QA モデルを通じて分析し、その結果をそのままデータ選択・シミュレーション生成のクエリとして再利用している点です。これにより、「失敗したからその近傍をすべて集める」という粗い戦略ではなく、「この種の失敗に最も寄与しているシナリオ構造を特定し、その構造を持つシーンだけを重点的に増やす」というより洗練されたデータ中心戦略が可能になります。

### 認知・推論ベンチマーク：ReCogDrive (2506.08052)

ReCogDrive は、単純な物体認識や距離推定を超えて、「運転者がどのように状況を理解し、どのようなリスクを認知しているか」という認知・推論レベルの能力を測るための VLM ベンチマークです。動画シーケンスに対するマルチステップ QA、因果関係を問う質問（「どの要因が危険度を上げているか」など）、反実仮想的な問い（counterfactual question）などを含みます。

ReCogDrive のようなベンチマークは、ラベルスキーマの観点では「どの認知要素を明示的にラベルとして持つべきか」を教えてくれます。例えば、

- 「遮蔽物の有無」「視界の妨げ」「他車の意図」「交通ルール遵守度」などを属性ラベルとして追加すべきかどうか。
- QA の失敗分析を通じて、「どの認知要素がモデルにとってボトルネックになっているか」を特定し、その要素を強調するようなシーンをデータ選択・シミュレーション生成で増やすべきかどうか。

といった議論がしやすくなります。

ReCogDrive の具体的な設計では、人間ドライバーの認知心理学の研究で用いられてきたタスク（例: 危険予測トレーニングやハザード知覚テスト）を参考にしつつ、それらを VLM が解ける QA 形式に落とし込んでいます。たとえば、「このシーンで最も注意すべき対象はどれか」「数秒後に衝突しそうな相手はどの車か」「もしこの歩行者が走り出したら、どのような危険が生じるか」といった質問が定義されており、単なる現在時点の状態推定ではなく、**潜在的な危険の想像 (hazard anticipation)** を評価することが重視されています。

このような認知レベルのラベルは、従来のデータセットではあまり明示化されていませんでしたが、ReCogDrive のようなベンチマークが普及することで、「危険候補の有無」「注意すべき対象の数」「残余リスク」といったメタラベルをデータカタログに格納する動機が強まると考えられます。Closed-Loop の運用では、実運用モニタリングで事故やヒヤリハットが発生した際に、その直前数秒間のシーンに対して ReCogDrive 型の QA を適用し、「モデルはどの危険候補を認識し損ねていたか」を分析することができます。その情報をもとに、「危険候補の見落としが多いシナリオ」を優先的に再収集・再ラベリングする、といったフィードバックループを構成できます。

### 行動理解とマルチグラニュラリティ：DriveAction (2506.05667)

DriveAction は、運転行動 (driving action) を複数の粒度（グラニュラリティ）でラベリングしたデータセット・ベンチマークです。例えば、「車線変更」「加速」「減速」といった低レベル行動に加え、「先行車に追従」「合流車を譲る」「歩行者を優先する」といった高レベル行動ラベルを持ちます。さらに、それらに対する自然言語説明や QA を付与し、VLM / VLA が行動の意味をどこまで理解できているかを評価します。

行動タクソノミの設計は、第 5 章全体の中でもとくに難しいテーマのひとつです。DriveAction のような公開ベンチマークは、「どの粒度で行動を分解すると、モデル評価やデバッグに役立つか」という実例を提供してくれます。実務では、

- 自社の ODD に合わせて、DriveAction の行動カテゴリをベースにクラス・属性を選抜・拡張する。
- DriveAction の評価セットを自社モデルに適用し、「どの行動種別で誤動作が多いか」を把握した上で該当シナリオのデータ選択・再ラベリングを行う。

といった Closed-Loop に直結した活用が考えられます。

DriveAction の論文では、行動ラベルを「瞬間的な操作レベル（例: ブレーキ・アクセル・ステアリング）」「マヌーバレベル（例: 車線変更・右左折・合流・追い越し）」「目的レベル（例: 前車追従・優先権の譲渡・危険回避）」といった複数の階層に分けて設計しています。さらに、各行動に対してそのトリガとなった環境要因（前方車の減速、歩行者の接近、信号の変化など）をメタラベルとして付与し、行動と環境の対応関係を分析できるようにしています。

このような階層的行動タクソノミは、ラベリングコストの観点からも有利です。例えば、すべてのフレームに詳細な目的レベルラベルを付けるのは現実的ではありませんが、まずはマヌーバレベルだけをラベリングし、その後 DriveAction 全体で学習したモデルを用いて目的レベルラベルを自動提案する、といった段階的な運用が考えられます。提案されたラベルのうち重要度の高いものだけを人間がレビューすれば、限られた工数で高粒度タクソノミを構築できます。

### 統合的蒸留：DiMA (2501.09757) による Multi-Ability Foundation Model

DiMA は、複数の専門モジュール（perception、prediction、planning など）や VLM / LLM からの知識を一つの driving policy に蒸留 (distillation) することを目指した手法です。Multi-Ability という名の通り、静的認識・動的予測・シーン理解・テキスト指示の解釈など、異なる「能力モジュール」を教師として用い、それらの出力を統合するようにポリシーネットワークを学習させます。

DiMA 型のアプローチでは、教師側の各モジュールが暗黙的に持っているタクソノミが、蒸留を通じてポリシー側に引き継がれます。ラベリング観点では、

- 教師モジュールが出す中間表現（検出結果・トラジェクトリ候補・リスクスコア・テキスト説明など）を、そのままデータセットのラベルとして保存し、後続の分析・可視化・シナリオマイニングに活用する。
- 蒸留後のポリシーと教師モジュール間の不一致を分析し、「どのタクソノミ要素が蒸留で失われているか」を洗い出す。

といった使い方が考えられます。これは、「モデルアーキテクチャの設計」だけでなく、「どのラベルをデータとして持ち、どのラベルを中間表現として捨てているか」という DataOps レベルの設計にも直結します。

DiMA のようなマルチアビリティ蒸留では、教師モジュール間でタクソノミの前提が微妙に異なることがしばしば問題になります。例えば、perception モジュールは「歩行者」と「自転車」に分かれたクラスラベルを前提としている一方で、prediction モジュールは両者をまとめた「脆弱道路利用者 (VRU)」として取り扱っている、といったケースです。論文では、こうした不整合を吸収するために、教師出力をいったん共通の中間表現（例: 行動タイプ・リスクレベル・相互関係）にマッピングし、そのうえでポリシーネットワークに蒸留する戦略が採用されています。

この発想は、ラベルスキーマ設計そのものにも応用できます。すなわち、「モデルごとにバラバラのラベル定義を持つ」のではなく、「シナリオ・行動・リスクといった共通軸で正規化されたタクソノミ」をまず定義し、それに各モジュールをマッピングする、というアーキテクチャです。Closed-Loop でデータを増やしていく際にも、この共通タクソノミをキーとしてデータセット・モデル・評価指標を結びつけておけば、「どのモジュールのどの能力を高めるために、どのデータをどれだけ追加したのか」を追跡しやすくなります。

## 5.3.1 のまとめと今後のトレンド

本節で見てきたように、近年の自動運転向け VLM / Foundation Model 研究は、単なる画像キャプション生成やオブジェクト検出の性能向上にとどまらず、

- QA ベンチマークを通じた **運転知識タクソノミの形式化**（DriveLM, DriveBench, STRIDE-QA, ReCogDrive など）
- BEV・HD マップ・シミュレーションとの統合による **シーン・シナリオのプログラマブルな定義**（Talk2BEV, SimLingo など）
- 自然言語付きポリシーモデル・エージェントによる **行動レベル・意思決定レベルのタクソノミ構築**（DriveGPT, EMMA, DriveAction, DiMA など）
- Foundation Agent による **Closed-Loop データエンジンの半自動化**（Poutine など）

といった方向に向かっていると考えられます。

データ中心・Closed-Loop の観点では、これらの研究成果を「モデル単体の性能向上」に閉じず、次のような設計に落とし込んでいくことが重要です。

- QA テンプレートや行動カテゴリを、そのままラベルガイドライン・タクソノミ案として取り込み、社内での議論のたたき台にする。
- VLM / VLA を用いたシーン検索・要約・説明生成を、データ選択・ラベリング・評価・シミュレーション生成の各段階とつなぎ、「エラー → シナリオ特定 → データ補完 → 再学習」というループを高速に回す。
- これらの自動化に過度に依存しないよう、Are VLMs Ready? が指摘する信頼性・ロバストネスの限界を前提に、人間レビューや保守的な運用ルールを組み込む。

第 6 章以降では、本節で紹介したような VLM / Foundation Model を、実際のトレーニングパイプライン・評価パイプラインにどのように組み込むかを具体的に議論していきます。その際、本節で取り上げたタクソノミ・ベンチマーク・エージェントのアイデアを、自社の ODD・組織・ツールチェーンに合わせてどのようにカスタマイズするかを意識して読み進めていただくとよいと思われます。
