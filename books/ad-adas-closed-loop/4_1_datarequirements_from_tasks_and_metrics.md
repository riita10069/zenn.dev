---
title: "4.1 タスクと指標からのデータ要件定義"
---

# 4.1 タスクと指標からのデータ要件定義

この節では、Perception / Prediction / Planning それぞれのタスクと評価指標から、どのようにデータ要件 (data requirements) を導出するかについて解説します。ODD (Operational Design Domain) セグメント（都市高速／郊外／降雪など）ごとの必要量を含め、タスク駆動でデータ要件を定義する考え方を整理します。データ中心・Closed-Loop の観点から、「モデルを作る前にデータ要件を言語化し、継続的に更新する」ことの重要性を強調します。

## タスクと評価指標からの逆算

まず、対象とするタスク（例: 3D 物体検出、車線検出、将来軌道予測、行動計画評価など）と、そのタスクに対して用いる評価指標（mAP, IoU, nuScenes Detection Score (NDS), ADE/FDE, collision rate, safety margin, comfort, efficiency 等）を明確にします。多くの実務プロジェクトでは、公開ベンチマーク（nuScenes、Waymo Open Dataset、KITTI など）の指標定義やデータ仕様を参考にしながら、自社の ODD と要件に合わせて指標をカスタマイズします。

次に、「その指標が統計的に安定して評価できるだけのデータがどの程度必要か」を逆算します。例えば、あるクラスの検出 mAP を ±1 ポイントの誤差範囲で推定したい場合、そのクラスの出現回数が数千〜数万サンプル必要になることが多いです。Planning タスクで「合流成功率 99% 以上」を評価したい場合、信頼区間を考慮すると最低でも数百〜数千の合流シーンが必要になります。

ここで重要なのは、「**指標ごとに必要なイベント数を見積もる**」ことです。

- 二値の成否指標（例: 合流成功 / 失敗、衝突有無）では、二項分布の信頼区間から必要サンプル数を見積もります。
- 連続値の指標（例: 最小距離、乗り心地指標、横加速度の標準偏差）では、分散の事前推定値をもとに、平均値の推定誤差が所望の範囲内になるようなサンプル数を見積もります。
- ロングテールクラス（歩行者飛び出し、逆走自転車など）は、統計的に安定した推定が難しいため、評価だけでなく「安全ケースを支える定性的エビデンス」としての扱いも併用します。

このような逆算は一度きりではなく、Closed-Loop で繰り返されます。初期段階では粗い見積もりでスタートし、実際の学習・評価・実車テストの結果から「どの指標の分散が大きいか」「どのクラスが慢性的にサンプル不足か」を観測しながら、必要量の見積もりを更新していきます。

### Perception タスクのデータ要件

Perception（物体検出・セマンティックセグメンテーション・インスタンスセグメンテーション・追跡など）では、以下の観点でデータ要件を整理します。

- クラスごとのサンプル数とバランス：歩行者・自転車・二輪車・大型車・工事車両など、ODD における重要クラスに十分なサンプルがあるかどうか。
- 条件ごとの多様性：昼夜、天候（晴れ・雨・雪・霧）、道路種別（高速・一般道・住宅街）、インフラ（信号・横断歩道・踏切）などの組み合わせ。
- センサ構成：マルチカメラ・LiDAR・Radar・マップ情報を用いる場合、それぞれのセンサが有効な状態で記録されているかどうか。

公開データセットの統計情報（クラス分布、天候分布、時間帯分布など）を参考に、自社のフリートログがどのような分布を持つかを比較することは、初期のギャップ分析として有効です。Perception 用のデータ要件を数字で定義する際には、「クラス × 条件」の表形式で目標サンプル数を記載し、実際の収集状況との乖離を定期的に確認します。

### Prediction / Planning タスクのデータ要件

Prediction（将来軌道予測）や Planning（経路・行動計画）は、フレーム単位ではなくシナリオ単位の指標を用いることが多いです。

- Prediction：平均距離誤差 (ADE)、最終距離誤差 (FDE)、マルチモーダル予測におけるトップ K の成功率、他車との衝突回避率など。
- Planning：シミュレーションやログリプレイ上での衝突率、車線維持率、制限速度遵守率、快適性（加減速度の尖り具合）、交通ルール違反数など。

これらの指標に対しては、以下のようなシナリオ軸でデータ要件を表現します。

- 交差点シナリオ（信号あり／なし、右折／左折／直進、交通量の多寡）。
- 合流・車線変更シナリオ（高速本線への合流、車線減少、ラウンドアバウト）。
- 脆弱な交通参加者（VRU: Vulnerable Road User）とのインタラクション（横断歩道を渡る歩行者、自転車の追い抜きなど）。

各シナリオタイプごとに、「少なくとも N シーンは評価セットに含める」「学習セットでは、このシナリオタイプごとに最低 M シーンを確保する」といった形で定量的な条件を定めると、後続のデータ選択・シーン検索・アクティブラーニングの基準として利用しやすくなります。

## ODD セグメントごとの必要量

第 2 章で扱った ODD セグメント（都市高速／郊外／降雪など）を軸に、各タスクごとの必要量を粗く見積もります。ODD は「どこで・どのような条件で・どのような速度レンジで・どのような交通ルールのもとでシステムが動作するか」を定義する枠組みです。ODD を軸にデータ要件を整理することで、「想定外の条件での評価不足」を早期に可視化できます。

- Perception：各 ODD セグメントでのオブジェクト密度やラベルの多様性を考慮し、クラスごとのサンプル数を定義します（例: 都市部夜間の歩行者 1 万インスタンス以上）。
- Prediction：交差点、合流、追い越しなどの行動シナリオごとのサンプル数を、ODD セグメント別に定義します（例: 降雪時の合流シナリオ 300 シーン以上）。
- Planning：シミュレーションやログリプレイで評価したいシナリオ数（例: 都市部での車線変更 1,000 シーン、右折 500 シーンなど）を目安として定義します。

実務では、ODD セグメント × シナリオ種別 × タスクの三次元表を作成し、

- どのセルが現状データ不足か。
- どのセルはデータは多いが性能が低いか。
- どのセルは十分な性能が出ているか。

を定期的にレビューします。これにより、「データ収集を増やすべきか」「ラベルポリシーやモデルアーキテクチャを見直すべきか」の意思決定がしやすくなります。

## 指標から必要サンプル数を見積もる実務的な手順

より実務的には、以下のような手順で必要サンプル数を見積もることが多いです。

1. ベンチマークや過去プロジェクトのデータセットから、暫定的な分散・誤差を推定する。
2. 目標とする評価精度（例: mAP ±1pt, 衝突率の 95% 信頼上限 0.1% 未満など）を決める。
3. 統計モデル（二項分布、正規近似など）を用いて必要サンプル数を計算する。
4. 実際のログから取得可能なサンプル数と比較し、ギャップを算出する。
5. ギャップを埋めるためのデータ収集・再ラベリング・合成データ生成の計画を立てる。

この過程で、データプロファイリングツールやメトリクス可視化ツールを活用すると効率的です。たとえば、特徴量分布やクラス分布をダッシュボードで確認できるデータカタログ／モニタリング基盤や、オープンソースのデータ品質可視化ツール（分布ドリフト検知や不均衡検出を行うライブラリなど）を組み合わせることで、定量的な議論を支援できます。

## Closed-Loop でのデータ要件更新とツール活用

データ中心・Closed-Loop の観点では、データ要件は固定文書ではなく、「モデル性能・実車での挙動・ヒヤリハット・インシデントの分析結果」に応じて継続的に更新されるべきです。

- オフライン評価・シミュレーション・実車テストの結果から、「どの ODD セグメント・シナリオで問題が多いか」をダッシュボードで可視化する。
- 問題が集中している領域について、シーン検索 UI やシナリオベース検索（第 4.7 節）を用いて追加データ候補を抽出する。
- アクティブラーニング（第 4.8 節）により、モデル不確実性や異常スコアの高いサンプルを優先度付きで抽出し、ラベリング・再学習に回す。

このループを支えるために、実務では以下のようなツール群を組み合わせることが多いです。

- ベンチマークデータセットの開発キットや評価スクリプト（例: nuScenes / Waymo Open Dataset の公式 devkit 相当のツール）を参考にした社内評価ツール。
- データプロファイリング・ドリフト検知ライブラリ（特徴量分布やクラス分布の変化を自動検知するツール）。
- 実験管理ツール（第 6 章）と連携したメトリクス集計基盤。

本書が想定する読者にとって重要なのは、特定のツール名ではなく、「タスクと指標からデータ要件を逆算する」という思考様式を身につけ、その結果を Closed-Loop の中で継続的に更新していく設計です。どのようなツールセットを選ぶにせよ、データ要件を明示的なテーブルやドキュメントとして管理し、モデル改善サイクルの中心に据えることが望ましいです。

