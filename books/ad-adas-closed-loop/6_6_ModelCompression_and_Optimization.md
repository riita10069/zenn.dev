# 6.6 モデル軽量化・省電力化・専用チップ向け最適化

この節では、モデル軽量化・省電力化・専用チップ向け最適化について解説します。量子化・枝刈り・蒸留、専用チップ向けグラフコンパイル（TensorRT 等）、リアルタイム制約とメモリフットプリントなどを整理し、データ中心・Closed-Loop の観点から「現実の制約を踏まえたモデル選択と評価」を考えます。

## 車載制約とモデル設計

自動運転・ADAS の実車環境では、GPU や専用アクセラレータが搭載されているとはいえ、データセンターと比べれば計算資源は限られています。また、リアルタイム性と安全性の観点から、レイテンシやメモリ使用量には厳しい制約があります。

- レイテンシ制約: センサ入力から制御出力までの end-to-end レイテンシが、数十ミリ秒〜数百ミリ秒以内に収まる必要があります。
- メモリ制約: 車載 SoC の DRAM 容量やキャッシュサイズに制限があり、大規模モデルをそのまま搭載することは難しい場合が多いです。
- 電力制約: 車載電源や熱設計の制約から、消費電力を抑える必要があります。

これらの制約を踏まえると、「学習時には大規模モデルを用いて性能を引き出しつつ、推論時には軽量なモデルに圧縮してデプロイする」戦略が一般的になります。

## 量子化・枝刈り・蒸留

モデル軽量化の代表的な手法として、量子化 (quantization)、枝刈り (pruning)、知識蒸留 (knowledge distillation) があります。

- 量子化: FP32 で学習したモデルを INT8 や FP16 / BF16 などに変換し、演算量とメモリ使用量を削減します。ポストトレーニング量子化 (post-training quantization) と量子化対応学習 (quantization-aware training) の 2 つのアプローチがあります。
- 枝刈り: 重みの一部をゼロ化することで、実質的なパラメータ数と FLOPs を削減します。構造化枝刈り（チャネルやフィルタ単位）と非構造化枝刈り（個々の重み単位）があります。
- 知識蒸留: 大規模な教師モデルの出力や中間表現を、小型の生徒モデルに模倣させることで、精度をなるべく保ちながらモデルを小型化します。

Closed-Loop の観点では、「本番で動作している軽量モデル」と「研究用途の大規模モデル」が共存することが多く、それぞれのモデルに対して別々の評価・再学習ループが存在します。例えば、大規模モデルで新しいアーキテクチャや学習戦略を検証し、十分な改善が確認できた段階で蒸留や量子化を施して車載モデルに反映する、といったプロセスです。

## 専用チップ向けグラフコンパイルと最適化

車載 SoC や専用アクセラレータ（GPU、DSP、NPU など）では、モデルを効率的に実行するためのグラフコンパイルが重要になります。代表的なツールとして、TensorRT、ONNX Runtime、TVM などがあり、以下のような最適化を行います。

- 演算の融合 (operator fusion): 連続する畳み込み・活性化・正規化などを一つのカーネルにまとめる。
- レイアウト最適化: ハードウェアに適したメモリレイアウト（NCHW / NHWC など）に変換する。
- 量子化の適用: INT8 演算ユニットを活用するために、事前にキャリブレーションや QAT を行ったモデルに変換する。

モデルアーキテクチャ側でも、これらのコンパイルツールがサポートしやすい構造（標準的な畳み込みや注意機構）を用いることが望ましいです。特殊な演算や動的な制御フローは、車載チップ上での実装が難しい場合があり、開発コストや検証コストが増大します。

## リアルタイム制約と Worst-Case 考慮

自動運転では平均レイテンシだけでなく、Worst-Case レイテンシやジッタ（ばらつき）も重要です。推論時間がたまたま長くなり、制御周期を外れてしまうと、安全上のリスクが高まります。

- Worst-Case 分析: ベンチマーク時には、平均・ p95・p99 などのレイテンシ指標に加え、最悪ケースや GC・キャッシュミス・OS スケジューリングなどによるスパイクを観測します。
- バックプレッシャ: 推論が間に合わない場合でも、安全側に倒す挙動（古い結果の再利用、保守的な fallback 制御など）を設計します。
- マルチスレッド設計: センサ処理・モデル推論・制御のスレッドを適切に分離し、モデル推論の遅延が他の機能に影響しないようにします。

Closed-Loop の観点では、シミュレーションや HiL (Hardware-in-the-Loop) 環境で実際の ECU と同等の条件でレイテンシ・スループットを計測し、その結果を第 8 章で扱うリリース判定やリグレッションテストの一部として取り扱います。

## データ中心のモデル軽量化戦略

モデル軽量化は、単にパラメータ数を減らすだけではなく、「どのデータに対してどの程度の表現力が必要か」を考えることが重要です。

- ODD 限定: 特定の ODD（例: 高速道路のみ）に機能を限定したモデルでは、一般的な市街地走行モデルよりも小さなモデルで高精度を達成できる場合があります。
- サブネットワークの活性化: 走行環境に応じてモデルの一部のみを活性化することで、平均計算量を削減する手法も研究されています。
- 圧縮後のデータ依存性: 量子化や枝刈りにより、特定の照度条件や距離レンジで性能が低下しやすくなる場合があるため、ODD セグメント別の評価が必須です。

Closed-Loop の中では、モデル軽量化の施策を適用した後に、必ずデータセットレベル（第 6.8 節）および Closed-Loop シミュレーション（第 7 章）で性能劣化や安全マージンの変化を確認し、その結果をもとに軽量化の度合いを調整することが求められます。

## モデルバージョニングとロールバック

軽量化・最適化されたモデルは、元の「リファレンスモデル」とペアで管理することが重要です。

- リファレンスモデル: GPU クラスタ上で動作する重量級モデル。研究用途やシミュレーションでの基準として利用します。
- デプロイモデル: 車載環境で動作する軽量モデル。量子化・蒸留・最適化が施されています。

これらのモデルは、実験トラッキング（第 6.1 節）やモデルレジストリ（第 8.1 節）でリンクされており、評価レポートやシミュレーション結果も対応付けられていることが望ましいです。問題発生時には、デプロイモデルからリファレンスモデルへのロールバックや、軽量化パラメータの緩和を迅速に行えるようにしておきます。
