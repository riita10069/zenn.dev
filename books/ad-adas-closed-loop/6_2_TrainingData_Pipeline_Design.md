---
title: "6.2 トレーニングデータパイプライン設計"
---

# 6.2 トレーニングデータパイプライン設計

この節では、大規模トレーニングデータパイプラインの設計について解説します。WebDataset のような大規模データローダ、On-the-fly 前処理とキャッシュ戦略、データバージョンとコードバージョンの整合を整理し、データ中心・Closed-Loop の観点から「データの流れとモデルの流れを同期させる」設計を考えます。

## 大規模トレーニングデータパイプラインの全体像

自動運転のトレーニングデータは、フリートから収集される膨大なログ（数 PB 規模になることもある）を元にしています。このため、単にファイルリストを読み込むだけではスループットが不足し、GPU が I/O 待ちでアイドルになる「GPU starvation」が発生しやすくなります。

典型的なトレーニングデータパイプラインは、次のような段階に分解できます。

1. データレイクからのサンプリング: データブラウザやメタデータクエリにより、訓練対象のシーン・フレームのリストを取得します。
2. シャーディング (sharding): WebDataset のようなフォーマットで、複数の小さなファイルを tar shard にまとめます。
3. ストリーミング読み込み: 分散ファイルシステムやオブジェクトストレージからネットワーク越しにストリーミングし、複数のワーカーで並列に展開します。
4. On-the-fly 前処理: 画像リサイズ、正規化、データ拡張、座標変換などを GPU ないし CPU でオンラインに実施します。
5. バッチ化・キューイング: 学習プロセスに渡す直前に、バッチ単位にまとめてキューに蓄えます。

Closed-Loop の観点では、このパイプラインに「インシデントデータ」「シミュレーション生成データ」「合成データ」など、複数のソースからのデータを混在させつつ、構成比率をコントロールできることが重要です。

## WebDataset 等によるストリーミング学習

多数の小さなファイル（画像・点群・ラベル JSON など）をそのままファイルシステムに置くと、メタデータ I/O がボトルネックとなりがちです。WebDataset や TFRecord のようなコンテナフォーマットを用いてシャーディングすることで、I/O 効率を高めることができます。

WebDataset の設計では、例えば以下のような構成が用いられます。

- 1 shard あたり数千〜数万サンプルを含む `.tar` ファイル。
- 各サンプルは複数のキー（例: `jpg`, `pcd`, `json`）で構成され、マルチモーダルデータを 1 レコードにまとめる。
- shard ID をランダムシャッフルし、さらに shard 内のサンプルもシャッフルしてからバッチを構成する。

PyTorch であれば、WebDataset ライブラリと `DataLoader` を組み合わせることで、分散学習 (Distributed Data Parallel) と親和性の高いストリーミングデータローダを構築できます。多数の GPU ノードで同じオブジェクトストレージを読む構成では、キャッシュレイヤ（ローカル SSD、NVMe キャッシュなど）を挟むことでネットワーク負荷を抑えることが一般的です。

## On-the-fly 前処理とキャッシュ戦略

前処理 (preprocessing) をどこまでトレーニング時に On-the-fly で行うかは、スループットと柔軟性のトレードオフになります。

- オフライン前処理: ログから学習用データを生成する段階で、センサ補正、座標変換、ground truth のアサインなどを済ませておき、トレーニング時には軽微な変換だけを行う。
- オンライン前処理: 正規化、データ拡張（ランダムクロップ、カラージッタ、ノイズ付加など）、ランダムなビュー合成（BEV 生成前のカメラ選択など）をトレーニング時に実施する。

オンライン前処理は柔軟である一方で、CPU/GPU に負荷を与え、学習スループットを下げる可能性があります。そのため、以下のようなキャッシュ戦略を設計することが多いです。

- 頻出の中間表現（例: BEV 特徴タイル、事前投影済み点群）を、中間キャッシュとして保存して再利用する。
- 重い前処理はデータパイプライン側のバッチジョブでまとめて実行し、学習パイプラインでは軽い変換に限定する。
- ハードウェアアクセラレータ（NVIDIA DALI や自社実装の GPU augment パイプライン）を利用し、GPU メモリ上で前処理を完結させる。

Closed-Loop の観点では、「新しいデータ種別がパイプラインに追加されたとき（例: 新しいセンサ構成、合成データソース）」に、どこまでオフラインで前処理しておくか、どこからをオンライン変換にするかを素早く切り替えられる柔軟性が重要です。

## データバージョンとコードバージョンの整合

トレーニングデータパイプラインでは、データバージョンとコードバージョンの不整合から、意図しないリークや評価ミスが発生することがあります。典型的な失敗例として、以下のようなものがあります。

- 古いデータスキーマ（ラベルフォーマットや座標系）が混在しており、一部のサンプルでラベルがずれている。
- データクリーニングロジックを更新したが、古いモデルの再学習時に新旧ロジックが混在した。
- 評価用データセットのバージョンが、過去の実験と微妙に異なっており、mAP の改善が本当にモデル改善によるものか判別できない。

これらを防ぐために、以下のようなルールと実装を設けることが有効です。

- データスキーマにバージョン番号を持たせ、読み込みコード側で期待するバージョンを明示的にチェックする。
- データセットバージョンをハードコードせず、設定ファイル (config) として管理し、実験トラッキングに記録する。
- データパイプラインとモデルコードの両方を同じ monorepo で管理し、Git のタグや commit hash によって整合を取る。

Closed-Loop では、インシデント由来データの取り込みやラベルポリシー変更が頻繁に発生します。そのたびにデータスキーマや前処理が更新されるため、「どのモデルはどのスキーマバージョンのデータで学習されたか」を必ずログに残し、過去モデルとの比較やロールバック時に混乱が生じないようにする必要があります。

## データサンプリングとミキシングの設計

トレーニングデータパイプラインにおいて、どのシーンをどの比率でサンプリングするかは、モデル性能に大きな影響を与えます。第 4 章で述べたデータ選択戦略と連携しつつ、パイプライン側で以下のような仕組みを設けます。

- ODD セグメント別サンプリング: 夜間・雨天・高速道路・市街地などのセグメントごとに、目標比率を設定してサンプルを抽出する。
- インシデント／ヒヤリハット強調: 直近のインシデント関連シーンを高い確率でサンプルするが、過学習を防ぐために上限比率を設ける。
- シミュレーション・合成データのミキシング: 実世界ログに対して、シミュレーション生成シーンや合成データを一定比率で混ぜる。

これらのサンプリングポリシーは、設定ファイルやデータベースに記録し、実験トラッキングと連携させます。Closed-Loop のサイクルでは、インシデントの分布や ODD での失敗傾向に応じて、サンプリングポリシーを継続的に更新していくことが重要です。

## パフォーマンス監視とボトルネック解析

最後に、トレーニングデータパイプラインのパフォーマンス監視について触れます。GPU 利用率やステップ時間だけでなく、I/O や前処理の各段階でメトリクスを計測し、ボトルネックを特定できるようにします。

- DataLoader 側で、バッチ読み込み時間の分布やキューの枯渇状況を計測する。
- CPU・GPU・ネットワークの利用率をメトリクスとして収集し、ダッシュボード上で可視化する。
- shard のサイズや数、キャッシュヒット率をログに残し、設計の見直しに活用する。

このような観測可能性を高めることで、Closed-Loop の再学習サイクルを回す際に「どこがボトルネックで、どの程度スケールさせる必要があるか」を定量的に判断しやすくなります。
