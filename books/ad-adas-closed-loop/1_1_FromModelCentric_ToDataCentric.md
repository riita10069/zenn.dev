# 1.1 モデル中心からデータ中心へ：自動運転開発パラダイムの転換

この節では、自動運転開発におけるパラダイムが、ルールベース／モデル中心 (model-centric) からデータ中心 (data-centric) へどのように移行してきたかを俯瞰します。従来の「モデルを改善する」発想と、近年重要性が増している「データを設計する」発想の違いを整理し、ロングテール (long-tail) な事象とデータ品質がなぜ安全性に直結するのかを説明します。あわせて、本書全体で扱う閉ループ (closed-loop) なデータエンジンの位置づけを簡単に紹介します。

## ルールベース／モジュラーから学習ベース／End-to-End へ

自動運転 (autonomous driving) の初期世代では、多くのシステムがルールベース (rule-based) あるいはモジュラー (modular) な構成をとっていました。センサーから取得した情報に対して、人間のエンジニアが条件分岐やしきい値を細かく設計し、「この条件のときは減速」「この条件のときは右折禁止」といったロジックをハードコードするスタイルです。知覚 (perception) も、クラシカルなコンピュータビジョンやシグナルプロセッシングのアルゴリズムが中心であり、統計的機械学習は補助的な位置づけであることが多かったです。

その後、深層学習 (deep learning) の発展や GPU ハードウェアの進化に伴い、画像認識・物体検出・軌道予測といったサブタスクはディープニューラルネットワークが主役となりました。DARPA Urban Challenge 以降の研究・産業両面の取り組みでは、車両周辺の環境認識や経路計画を複数のモジュールに分割し、それぞれを学習ベース (learning-based) のモデルで置き換えていく流れが強くなりました。

代表的な例として、NVIDIA による End-to-End Learning for Self-Driving Cars (Bojarski et al., 2016) では、フロントカメラ画像から操舵角を直接推定する CNN ベースのパイロットネット (PilotNet) が提案されています。また、ChauffeurNet や Waymo / Cruise / Tesla など各社の公開事例では、カメラ・LiDAR・Radar を入力とした知覚モジュール、軌道予測モジュール、経路計画モジュールをニューラルネットワーク化したモジュラー構成が詳細に説明されています。

このような流れの中で、開発の焦点は「より複雑なモデルアーキテクチャを試す」「より大きなネットワークを学習する」といったモデル中心 (model-centric) な探索に向かいがちでした。ハイパーパラメータ探索、ネットワーク深度・幅の拡大、新しい損失関数の設計などです。しかし、自動運転という実世界タスクでは、モデル側を大きく変更しても性能が頭打ちになる場面が少なくありませんでした。特に、KITTI、nuScenes (Caesar et al., 2020)、Waymo Open Dataset (Sun et al., 2020) など決まったベンチマークに対しては mAP や精度が飽和しつつある一方で、実運用フリートでのロングテール事象に対する失敗は依然として残り続けることが報告されています。

## モデル中心 (model-centric) アプローチの限界

モデル中心のアプローチでは、固定された学習データセットを前提として、「このデータセット上で最高のスコアを出すモデル」を追求します。学術コンペティションでは有効な戦略ですが、道路環境のように多様で変化し続ける世界に対しては、いくつかの限界があります。

- データセットが現実世界を十分にカバーしていない場合、どれだけモデルを変えても実運用での性能は向上しないことが多いです。
- ラベリング方針や品質にばらつきがあると、モデルはラベルのノイズに適応してしまい、本来学習すべきパターンを正しく学べない可能性があります。
- 実運用環境で発生する新種のシーン（例: 新しい交通ルール、未知の道路工事パターンなど）が学習データに存在しない場合、モデルは分布外 (out-of-distribution) の入力に対して不安定な挙動を示します。

自動運転では、これらの問題が安全性と信頼性に直結します。検出漏れや誤検出がまれにしか起こらないとしても、その「まれ」が重大事故につながりうるためです。したがって、「ベンチマークデータセット上での平均性能」だけではなく、「現実世界でのロングテールなシーンに対する堅牢性」を重視した評価が必要になります。

近年の Data-Centric AI (Andrew Ng, 2021 など) の議論では、「モデルは十分に強力であることが多く、性能のボトルネックはデータ品質やラベル一貫性にある」と指摘されています。自動運転でも、モデル改良よりもデータ収集・ラベリング・評価の設計が性能を左右するケースが増えていると考えられます。

## データ中心 (data-centric) アプローチとロングテール問題

データ中心 (data-centric) アプローチでは、「モデルのアーキテクチャはある程度固定し、その代わりにデータの質と多様性を徹底的に改善する」ことに重点を置きます。具体的には、以下のような活動が主戦場となります。

- どのようなシーンが現行モデルにとって難しいかを分析し、難例 (hard case) を体系的に収集・ラベリングする。
- ラベルポリシーを明文化し、ラベラー間のばらつきを減らすとともに、一貫性のあるラベル品質指標を設ける。
- データ収集フリートやシミュレータを活用して、特定のシナリオ（例: 夜間の横断歩道、高速道路の合流部、悪天候時の自転車など）を意図的に増やす。

特に重要なのがロングテール (long-tail) 問題です。道路交通環境には、頻度は低いが安全上クリティカルな事象が数多く存在します。例えば、「ほぼ停止しているバスの陰から突然歩行者が現れる」「珍しい特殊車両が逆光の中で走行している」「積雪でレーンマークがほとんど見えない」といったケースです。これらの事象は統計的には少数派ですが、見逃すと致命的な事故につながりかねません。

ロングテールな事象に対して堅牢なモデルを作るためには、モデルの表現力だけでなく、そのようなシーンを十分に含むデータセット設計と、適切なラベリング・評価指標が不可欠です。データ中心の考え方では、「どのようなロングテール事象を、どれくらいの頻度で、どのようなラベル定義で集めるか」を設計することが、モデル設計と同等かそれ以上に重要な仕事になります。

実際、nuScenes や Waymo Open Dataset のような大規模データセットでは、夜間・悪天候・複雑交差点などを意図的に含めることが強調されていますが、それでも商用サービスで観測されるロングテールのごく一部しかカバーできていないと報告されています。商用フリートレベルでは、ペタバイト級のログから特定のレアイベント（例: 横断歩道外横断、自転車の逆走、特殊車両の合流など）をマイニングし、追加ラベリングやシミュレーションに回す仕組みが構築されつつあります。

また、長期運用を前提とすると、「今日のロングテール」が明日には「よくあるシーン」になることもあります。新しい信号機のデザイン、新しい道路標識、マイクロモビリティ、新しい交通ルールなど、環境変化に伴って「まれ」の中身も変化します。データ中心・Closed-Loop の観点では、ロングテールを固定されたリストとして扱うのではなく、継続的にアップデートされる「動的な関心リスト」として扱う必要があると考えられます。

## 閉ループ (closed-loop) なデータエンジンの必要性

ロングテール問題に継続的に対処するためには、一度データセットを構築して終わりにするのではなく、実運用からのフィードバックを取り込み続ける閉ループ (closed-loop) な仕組みが必要です。本書でいう Closed-Loop データエンジンとは、以下のような循環プロセスを指します。

1. 実世界またはシミュレーションからデータを収集する。
2. データを保存・整理し、検索可能な形で管理する。
3. モデルの弱点に基づいてデータを選択し、必要に応じて追加ラベリングやオートラベリングを行う。
4. モデルを再学習し、オフライン評価およびシミュレーションによる Closed-Loop 評価を行う。
5. 改善したモデルを実世界に展開し、オンラインモニタリングにより新たな課題シーンを発見する。

このサイクルを継続的に回すことで、環境変化や新たなロングテール事象に対応し続けることができます。重要なのは、データ収集・ラベリング・学習・評価・運用が、それぞれ孤立したプロセスとして存在するのではなく、一体となったデータエンジンとして設計されている点です。

Andrew Ng らが提唱する Data-Centric AI のプラクティスでは、「データのエラーパターンを分析 → ラベルガイドライン改善 → 難例の追加収集 → モデル再学習」というサイクルを高速に回すことが推奨されています。自動運転ではこれに加えて、オンラインモニタリング・シミュレーション・安全評価など複数のフィードバック経路が存在します。本書で扱う Closed-Loop データエンジンは、こうした多様なフィードバックを 1 つのパイプラインにまとめるための枠組みと考えられます。

## 本書全体との関係

本章では、モデル中心からデータ中心へのパラダイム転換と、その背景にあるロングテール問題・データ品質の重要性を概観しました。以降の章では、この Closed-Loop データエンジンを 7 段階に分解し、各段階における実務上の設計ポイントやアンチパターン、具体的なツール・アーキテクチャ例を詳しく解説します。

読者のみなさんには、単に「より良いモデル」を追い求めるのではなく、「より良いデータ」「より良いフィードバックループ」を設計することこそが、自動運転システム全体の安全性と開発効率を高める鍵である、と意識して読み進めていただきたいです。
継続的に行いながら、モデル・評価・運用全体を一体として改善していくことが重要です。

## 「モデルをいじる」から「データをいじる」への実務的シフト

ここまでの議論を、実務のワークフローの観点からもう少し具体的に整理します。モデル中心 (model-centric) とデータ中心 (data-centric) の違いは、単にスローガンの違いではなく、日々の開発サイクルがどのようなステップで構成されているかに現れます。

典型的なモデル中心ワークフローは、次のような形になることが多いです。

1. 既存の学習データセット（固定）を用意する。
2. 新しいモデルアーキテクチャ・損失関数・正則化手法を提案する。
3. ハイパーパラメータ探索を行う。
4. ベンチマークデータセット上の指標を比較し、最も高いスコアのモデルを採用する。

このループでは、「入力として与えられるデータ」をほとんど変えないまま、モデル側の工夫に開発時間の大半を費やすことが多いです。一方で、データをいじる（data-centric な）ワークフローでは、次のようなステップが主役になります。

1. 既存モデルのエラー分析を行い、どの ODD・どのシナリオ・どのクラスで失敗が多いかを可視化する。
2. 失敗パターンごとに、ラベルポリシーの曖昧さやデータ不足の有無を調査する。
3. 必要に応じてラベルガイドラインを更新し、既存データの再ラベリングを行う。
4. フリートやシミュレータから、弱点シナリオを意図的に収集・ラベリングする。
5. データセット構成（クラスバランス、ODD カバレッジ、Long-tail セットなど）を再設計し、同じモデルアーキテクチャで再学習・評価する。

もちろん、現実のプロジェクトでは両者が混在し、「モデルもデータも両方改善する」ことがほとんどです。ただし、どちらに時間と組織的リソースの多くを投下しているかによって、結果として得られる性能と開発効率は大きく変わります。近年の大規模自動運転プロジェクトでは、モデルアーキテクチャの革新よりも、データパイプラインやラベリング・評価の設計に多くの人員が割かれる傾向が強まっていると考えられます。

## ロングテール問題の定量的な捉え方

ロングテール (long-tail) 問題をより技術的に理解するために、簡単な定量的視点を紹介します。多くの実運用フリートでは、走行時間に対する特定イベントの発生頻度を統計的に分析しており、「ごく一部のイベントが非常に高頻度で現れ、大多数のイベントが極めて低頻度でしか現れない」というパワーロー（冪乗則）的な分布が観測されることが多いです。

例えば、以下のようなざっくりとした分類を考えます。

- 日常的イベント: 直進・車線維持・緩やかなカーブなど、ほぼ常に発生しているシーン。
- 頻出イベント: 一般的な車線変更・合流・右左折など、数分〜数十分に一度発生するシーン。
- まれなイベント: 急ブレーキ、近接オブジェクト、強い渋滞、複雑な交差点など、数時間〜十数時間に一度発生するシーン。
- ロングテールイベント: AEB 介入、ドライバの急介入、特殊車両との遭遇、異常な他車挙動など、数百時間〜数千時間に一度しか発生しないシーン。

モデル中心の発想では、学習・評価ともに日常的イベントと頻出イベントが統計的に支配的になりがちで、ロングテールイベントに対する性能は平均値に埋もれてしまいます。データ中心の発想では、これらロングテールイベントを明示的に抽出し、別枠の Long-tail データセットとして管理・評価することが重要です。

技術的には、イベント頻度分布のログ・ログプロットを取り、特定閾値より出現頻度が低いイベントを Long-tail と定義する、あるいは ODD・クラス・シナリオごとに「1,000 サンプルあたりの失敗数」を推定し、その信頼区間から必要なサンプル数を逆算するといった方法があります。これらの詳細は第 4 章と第 7 章で、実際のデータセット設計・シミュレーション評価の文脈で再度取り上げます。

## 組織・プロセス視点でのパラダイム転換

モデル中心からデータ中心への転換は、技術的な話題だけでなく、組織構造や責任分担にも影響します。モデル中心の組織では、「モデルチーム」が主役となり、データは比較的静的な前提条件として扱われることが多いです。一方、データ中心の組織では、以下のような専任ロールが登場し、互いに密に連携しながら Closed-Loop を回します。

- Data Engineering / Data Platform チーム: ログ収集、インジェスト、データレイク、カタログ、シーン検索などを担当します。
- Labeling Ops / Annotation チーム: ラベルポリシー策定、ラベリングベンダー管理、品質管理を担当します。
- ML / AD Model チーム: モデル設計・学習・オフライン評価を担当し、エラー分析結果を Data / Labeling チームにフィードバックします。
- Simulation / Test チーム: シナリオベース評価や Closed-Loop シミュレーションを担当し、テスト結果を Data / ML チームに戻します。
- Onboard / Vehicle Integration チーム: 車両実装・OTA・オンラインモニタリングを担当し、実運用のシグナルをデータエンジンに届けます。

このように、データ中心・Closed-Loop な開発を行うためには、単に「データを見よう」と呼びかけるだけでは不十分であり、組織とプロセスの設計を通じて、データ収集から運用までのフィードバックループを構造的に支える必要があります。本書の残りの章では、それぞれのロールがどのような技術スタックと指標を持ち、どのように情報をやりとりするべきかを具体的に掘り下げていきます。

## 補足: モデル中心評価指標の落とし穴とデータ中心指標

最後に、モデル中心 (model-centric) な評価指標の落とし穴と、それを補完するデータ中心 (data-centric) な指標の考え方を簡単に整理しておきます。多くの研究・実装では、mAP や IoU、ADE/FDE などの平均的な指標を用いてモデル性能を比較しますが、自動運転という安全クリティカルな文脈では、これらの指標だけでは不十分であることが多いです。

例えば、ある物体検出モデルが「全体の mAP は 0.70 → 0.72 に向上した」と報告されたとしても、その向上がどのシナリオに由来するかを見なければ、安全性へのインパクトは判断できません。日常的な高速道路直進シーンでの性能が向上しただけなのか、夜間の横断歩道や混雑した交差点での歩行者検出性能が向上したのかでは、意味が大きく異なります。

データ中心・Closed-Loop の観点では、以下のような「分解された指標」や「データ側の指標」を併用することが重要になります。

- ODD セグメント別指標: 都市高速／郊外／降雪など、ODD セグメントごとに mAP や衝突リスク指標を分解して集計する。
- シナリオ別指標: 右折・合流・追い越し・横断歩道などのシナリオ単位で、成功率やヒヤリハット発生率を評価する。
- Long-tail セット指標: ロングテールイベントのみから構成されるデータセット上での性能（例: Long-tail mAP、Long-tail collision rate）を別途追跡する。
- データ品質指標: 露出やノイズ、キャリブレーション状態など、データそのものの品質に関する指標を併せてモニタリングする。

実務では、これらの指標をダッシュボードとして可視化し、「どのモデルバージョンがどの指標をどれだけ改善・悪化させたか」を一目で確認できるようにすることが多いです。第 6 章と第 7 章では、具体的なオフライン評価・シミュレーション評価の設計を扱いますが、その前提として、本節で述べたような「評価指標の分解とデータ中心指標の併用」が重要であることを意識しておいてください。

### ミニケーススタディ：mAP 改善なのにヒヤリハットが減らない理由

最後に、実務でよく起こりうる状況を、架空のケーススタディとして描いてみます。

あるチームでは、都市部 ADAS 向けの歩行者検出モデルを開発しており、ベンチマークデータセット上の mAP を 0.68 から 0.72 へと改善することに成功しました。論文的には十分に魅力的な数字であり、社内レビューでも好意的に受け止められました。しかし、実運用フリートから集計したヒヤリハット統計を見ると、「夜間・雨天・横断歩道」のシナリオにおける歩行者関連のヒヤリハット件数がほとんど減っていないことがわかりました。

エラー分析を行った結果、次のような事実が判明しました。

- ベンチマークデータセットでは、晴天・昼間・良好な視認性のシーンが大半を占めており、夜間・雨天シーンはごく一部しか含まれていなかった。
- モデル改良により、日常的なシーンでの検出精度は向上していたが、そもそも夜間・雨天のサンプル数が少ないため、その領域での性能はほとんど変わっていなかった。
- ラベルポリシー上、横断歩道付近の歩行者の定義が曖昧であり、アノテータ間のばらつきが大きかった。

このケースでは、「モデルをいじる」だけでは安全性のボトルネックを解消できないことが明確です。データ中心・Closed-Loop の観点では、次のような対策が自然に導かれます。

1. 夜間・雨天・横断歩道シーンを明示的なシナリオタグとして定義し、ラベルポリシーを具体的な例とともに整理する。
2. オンラインモニタリングで検出されたヒヤリハット・介入シーンから、該当シナリオのログをマイニングし、Long-tail セットとしてラベリングする。
3. 新たに構築した Long-tail セット上の性能指標（例: Night-Rain Crosswalk mAP、関連シナリオのヒヤリハット率）を定義し、モデル更新ごとに追跡する。

このように、評価指標とデータセット設計を見直すことで、同じモデルアーキテクチャであっても「現場で本当に減らしたいリスク」に対して直接作用する改善サイクルを構築できます。本書全体を通じて、読者のみなさんには「モデル改良の前に、データと指標の設計を見直す」という視点を常に念頭に置いていただきたいです。

現実のプロジェクトでは、ここで述べたような分析・対策を一度行って終わりにするのではなく、運用開始後も継続的に繰り返していくことが求められます。フリート規模の拡大や ODD の拡張、新たな機能追加に伴い、ロングテールの中身や優先度は時間とともに変化していきます。その変化をデータと指標のレベルで捉え、Closed-Loop に反映し続ける体制こそが、「データ中心の自動運転開発」と呼べる状態であると考えられます。

次節以降では、自動運転スタック全体の構造と、その中でデータと機械学習タスクがどのように位置付けられるかを整理しながら、「どのレイヤーからどのようなフィードバック信号を取り出し、どのレイヤーにどのようなデータを戻すべきか」という、より具体的な設計論に進んでいきます。

