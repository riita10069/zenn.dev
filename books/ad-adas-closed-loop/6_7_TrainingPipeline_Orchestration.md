---
title: "6.7 トレーニングパイプラインのオーケストレーション"
---

# 6.7 トレーニングパイプラインのオーケストレーション

この節では、トレーニングパイプラインのオーケストレーションについて解説します。Dag ベースのワークフロー、定期再学習・モデル更新スケジュール、トレーニングガバナンスと承認プロセスを整理し、データ中心・Closed-Loop の観点から「継続的学習を組織的に運用する」仕組みを考えます。

## Pipeline as Code と DAG ワークフロー

トレーニングパイプラインのオーケストレーションでは、「Pipeline as Code」という考え方がよく用いられます。これは、データ抽出・前処理・学習・評価・モデル登録・デプロイ準備といった一連のステップを、コード（YAML/DSL や Python スクリプト）として記述し、DAG (Directed Acyclic Graph) として実行するアプローチです。

- 代表的な基盤: Kubeflow Pipelines, Apache Airflow, Flyte, Argo Workflows など。
- ステップの分解: 「データセット生成」「ラベリングジョブ」「トレーニングジョブ」「オフライン評価」「シミュレーションキック」「モデル登録」「リリース判定」など。
- 依存関係: 例えば「オフライン評価はトレーニング完了とデータセット生成完了の両方に依存する」といった依存関係を DAG で表現します。

Pipeline as Code により、パイプラインの変更が Git でレビュー可能になり、再現性や監査性が向上します。また、閉ループの各ステージ（第 2〜5 章のデータパイプライン、第 7〜8 章の評価・デプロイパイプライン）を横断的に接続する枠組みとしても機能します。

## 定期再学習とイベント駆動再学習

トレーニングパイプラインのスケジューリングには、定期再学習 (periodic retraining) とイベント駆動再学習 (event-driven retraining) の 2 つのパターンがあります。

- 定期再学習: 週次・月次などのスケジュールに基づき、最新のデータスナップショットからモデルを再学習し、性能や分布シフトをチェックします。
- イベント駆動再学習: インシデント・KPI の悪化・新機能の導入など、特定のイベントをトリガとして再学習パイプラインを起動します。

Closed-Loop の観点では、これらを組み合わせて運用することが一般的です。例えば、通常は月次の定期再学習を行いつつ、重大インシデント発生時にはイベント駆動でハイプライオリティのパイプラインを走らせる、といった構成です。

## トレーニングガバナンスと承認プロセス

自動運転システムでは、安全性と法令遵守の観点から、モデル更新には明確なガバナンスが求められます。トレーニングパイプラインにも、適切な承認プロセス (approval workflow) を組み込む必要があります。

- モデル更新リクエスト: 新しいデータセットやアーキテクチャに基づき「モデル更新リクエスト」を起票し、目的・変更内容・想定影響範囲を記載します。
- 自動テストゲート: パイプライン内に、オフライン評価・シミュレーション・HiL テストの結果に基づくゲートを設け、基準を満たさない場合は自動的に停止させます。
- 人的レビュー: 安全担当・機能オーナーによるレビュー・承認ステップを設け、最終的なリリース可否を判断します。

これらのプロセスは、第 8 章で扱うリリースプロセスとも密に連携します。トレーニングパイプライン側で「リリース候補モデル (release candidate)」を生成し、評価・承認を経て「本番用モデル」としてモデルレジストリに登録するフローを設計します。

## メタデータ駆動のオーケストレーション

第 6.1 節で述べた実験メタデータは、トレーニングパイプラインのオーケストレーションとも密接に関係します。パイプラインの各ステップが、どの experiment / run / dataset version に紐づくかを明示的に管理することで、以下のようなメリットが得られます。

- 失敗時のトレース: あるモデルが本番で問題を起こした場合、そのモデルがどのデータ・どのラベルポリシー・どの実験から生まれたかを素早く追跡できる。
- 再実行の自動化: 過去のパイプライン実行履歴から、同じ設定で再実行する「Rerun」機能を実装しやすくなる。
- 影響範囲の可視化: 特定のデータソースや前処理ロジックに変更があった場合、影響を受けるモデルや実験を一覧できる。

このようなメタデータ駆動のオーケストレーションは、規模が大きくなるほど重要性が増します。Closed-Loop を継続的に回す中で、変更履歴と改善効果を体系的に蓄積するための基盤となります。

## 失敗を前提としたパイプライン設計

大規模なトレーニングパイプラインは、途中で何らかのジョブが失敗することを前提に設計する必要があります。

- 冪等性 (idempotency): 各ステップを再実行しても副作用が重複しないようにし、部分的な再実行を容易にします。
- リトライポリシー: 一時的なネットワークエラーやリソース不足に対しては自動リトライし、恒久的なエラー（コードバグ・データ不整合）に対しては早期に人間へアラートを上げます。
- アラートとダッシュボード: 失敗率、キュー滞留時間、成功までの lead time などを監視し、ボトルネックを継続的に改善します。

Closed-Loop の観点からは、パイプラインの安定性がそのまま「データから学習・評価までを回す速度」に影響します。特に、インシデント対応のような緊急パイプラインでは、失敗なく一気通貫で完了できることが重要です。

## 開発者体験 (DX) とパイプライン

最後に、開発者体験 (Developer Experience, DX) の観点からもトレーニングパイプラインを設計することが重要です。

- ローカル・小規模クラスタでのデバッグ: 本番パイプラインと同じコードを用いて、小規模データセットで素早く実験できる環境を用意します。
- テンプレート化: 新しい機能やアーキテクチャの実験に共通のパイプラインテンプレートを用意し、設定ファイルの変更だけで新パイプラインを立ち上げられるようにします。
- ドキュメンテーション: 各パイプラインの目的・入力・出力・依存関係を文書化し、誰でも理解しやすいようにします。

このような設計により、個々の研究者・エンジニアが Closed-Loop の一部だけに閉じることなく、全体像を把握しながら改善サイクルに貢献しやすくなります。
