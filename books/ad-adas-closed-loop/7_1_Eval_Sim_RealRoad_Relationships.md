---
title: "7.1 評価・シミュレーション・実車テストの関係"
---

# 7.1 評価・シミュレーション・実車テストの関係

この節では、評価・シミュレーション・実車テストの関係について解説します。Unit / Component / System / Vehicle / Fleet レベル評価、オフライン指標 vs Closed-Loop 挙動 vs 実車テストの役割分担を整理し、データ中心・Closed-Loop の観点から「どのレベルの評価結果をどのデータサイクルに戻すか」を考えます。

## 評価レベルの階層構造と目的

自動運転・ADAS の評価は、一般的に次のような階層で整理されます。

- Unit レベル: 1 つの関数やモジュールに対するユニットテスト (unit test)
- Component レベル: Perception / Prediction / Planning などコンポーネント単位の評価
- System レベル: 自動運転スタック全体を対象とした Software-in-the-Loop (SiL) / Hardware-in-the-Loop (HiL)
- Vehicle レベル: 実車を用いた試験場テスト・限定された公道テスト
- Fleet レベル: 大規模フリート運用時のテレメトリに基づく統計的評価

各レベルは「どのような仮定のもとで、何を確認するか」が異なります。例えば Unit / Component レベルでは、入力分布をある程度コントロールしたうえでアルゴリズムの性質を詳細に調べることが多いです。一方 System / Vehicle レベルでは、センサー誤差や制御遅延なども含めた Closed-Loop 挙動を確認し、「システムとして破綻しないか」「安全側の挙動になっているか」を見ることが主眼になります。

データ中心・Closed-Loop の観点では、どのレベルの評価結果も最終的にはデータエンジンに戻され、次のような意思決定に使われることが望ましいです。

- どの ODD セグメントでデータが不足しているか
- どの機能が原因で失敗している可能性が高いか
- どの種別のシナリオを追加で収集・生成すべきか

## オフライン評価と Closed-Loop 評価の違い

オフライン評価 (offline evaluation) とは、固定されたデータセットに対してモデル出力を計算し、mAP、IoU、ADE/FDE、成功率などの指標を集計する形式の評価を指します。第 6 章で扱ったように、Perception / Prediction / Planning それぞれに代表的なオフライン指標が存在し、実験スピードも速いため、日々の開発ではオフライン評価が主役になることが多いです。

一方で、自動運転システム全体の安全性やユーザー体験は、オフライン指標だけでは十分に説明できないことが知られています。例えば、以下のようなケースが典型です。

- 検出 mAP は高いが、わずかな遅延やノイズにより追従制御が不安定になる。
- 将来軌道の平均誤差は小さいが、ごく稀に衝突に近い挙動を選択してしまう。
- 個々のコンポーネントは仕様を満たしているが、組み合わせた結果として乗り心地が悪くなる。

このような挙動は、環境・他車・制御のフィードバックを含めた Closed-Loop 評価でなければ観測しにくいです。したがって、実務では以下のような関係性を意識しておくと良いです。

- オフライン評価: モデルの「静的な性能」を高速に比較し、リグレッションを検知する。
- Closed-Loop 評価 (SiL / HiL / 実車): システムとしての「動的な挙動」を確認し、安全性・快適性・効率などの指標を測る。

データ中心の視点では、オフライン評価で見つかった弱点をシナリオ DB に落とし込み、それを Closed-Loop 評価に流し込む、というループ設計が重要になります。

## 実車テスト・公道試験の位置づけ

実車テスト (vehicle test) や公道試験は、自動運転システムの最終的な検証ステージとして不可欠です。一方で、安全性・法令・社会受容性の観点から、実車テストの範囲や頻度には厳しい制約があります。

- テスト可能なシナリオは、事前にリスクアセスメントが行われ、限定的な ODD に絞られることが多いです。
- 危険なシナリオを意図的に多数発生させることは原則としてできません。
- 大規模シナリオカバレッジを実車のみで達成しようとすると、時間・コストともに現実的ではありません。

そのため、実車テストは次のような役割を担うことが多いです。

- シミュレーションではモデル化が難しい現象（路面の微小な凹凸、センサー汚れ、ドライバーや歩行者の微細な挙動）を含む現実世界での性能確認。
- システム統合後の最終確認（安全モニタリング機構、フェイルセーフ、HMI などを含めた全体としての挙動）。
- 規制や認証プロセス上、必須とされる試験ケースの実施。

データ中心・Closed-Loop の観点では、実車テストで得られたログやインシデントは、特に優先度の高いシナリオとしてシナリオ DB に登録し、第 4〜6 章で扱ったデータ選択・ラベリング・学習パイプラインにフィードバックしていくことが重要です。

## System / Vehicle レベル評価の設計パターン

System / Vehicle レベルの評価設計では、以下のような観点を整理しておくと、Closed-Loop 評価とオフライン評価の橋渡しがしやすくなります。

- 評価対象:
  - Perception モジュールのみをリアルタイムで差し替えるのか
  - Planning まで含めたフルスタックなのか
  - 制御や車両ダイナミクスまで含めた End-to-End か
- 入力データ:
  - 完全に合成されたセンサデータか（フルシミュレーション）
  - 実車ログのリプレイか（ログリプレイ・世界モデル）
  - 合成と実ログを組み合わせたハイブリッドか
- 評価指標:
  - 衝突・ニアミスなどの安全関連指標 (safety metrics)
  - 乗り心地・加速度・ジャークなどの快適性 (comfort)
  - 到達時間・燃費・交通流への影響などの効率 (efficiency)

これらを明示的に設計しておくことで、「どの評価ステージでどの指標を見ているか」「どの指標がリリースゲートに使われているか」が共有しやすくなります。第 8 章で扱うリリースゲート設計と一貫した枠組みを用いることが望ましいです。

## 評価結果のトレーサビリティとデータフロー

データ中心・Closed-Loop の観点で特に重要なのは、評価結果からデータやシナリオへ遡れるトレーサビリティ (traceability) です。例えば、以下のような質問に即座に答えられる状態を目指します。

- 「このシミュレーションシナリオで衝突が発生したが、そのシナリオはどの実車ログから生成されたか？」
- 「この実車インシデントに類似したシナリオはシミュレーション上にどれくらい存在し、どのバージョンのモデルで失敗しているか？」
- 「特定のオフライン指標が悪化したとき、それに対応する Closed-Loop シナリオ群では何が起きているか？」

そのために、評価パイプラインでは少なくとも以下のようなメタデータを統一的に管理しておくことが望ましいです。

- シナリオ ID（シナリオ DB 内で一意なキー）
- シミュレーション構成 ID（センサ設定・物理モデル・ソフトウェアバージョン）
- モデルバージョン ID（学習条件・データセットバージョンを含む）
- 評価ジョブ ID（実行日時・担当者・環境情報など）

これらをキーとして、シナリオ DB、ログストレージ、実験管理ツール、レポート生成ツール（第 7.8 節）を結び付けることで、Closed-Loop データエンジン全体として「評価結果がどのデータに由来するか」を追跡できるようになります。

## Closed-Loop データエンジンへのフィードバック

最後に、本節を第 1〜6 章までの議論と結び付けます。評価・シミュレーション・実車テストの結果は、次のような流れで Closed-Loop データエンジンに戻されることが多いです。

1. 評価結果から失敗シナリオや性能ギャップを抽出する（第 7.2〜7.6 節）。
2. シナリオをキーとして、対応する実車ログ・シミュレーションログをデータレイクから取得する（第 3 章）。
3. 必要に応じて追加ラベリングやリラベリングを行い（第 5 章）、新しいトレーニングデータセットを設計する（第 4 章）。
4. モデルを再学習し（第 6 章）、オフライン評価→ Closed-Loop 評価→ 実車・フリート評価というサイクルを再び回す。

このループを継続的に回し続けることで、単発の「テストの実施」から、「評価結果を起点としたデータ中心・Closed-Loop 改善サイクル」へと組織の文化をシフトさせていくことが狙いとなります。
