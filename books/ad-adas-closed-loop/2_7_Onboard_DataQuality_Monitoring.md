# 2.7 オンボードでのデータ品質・健全性モニタリング

この節では、車両上でリアルタイムにデータ品質・健全性 (data quality & health) を監視する仕組みについて解説します。センサー故障検知やログ欠損検知、露出・ノイズ・パケットドロップなどのリアルタイム統計をどのように設計するかを整理します。データ中心・Closed-Loop の観点から、オンボードのモニタリングが後続のデータクレンジングやフリート運用にどのように寄与するかを説明します。

## センサー故障検知・ログ欠損検知

センサーやロガーに問題が発生すると、その期間のデータは学習や評価にほとんど利用できなくなります。無駄なデータ収集を避けるためにも、オンボードでの故障・欠損検知が重要です。

代表的なチェック項目として、以下のようなものがあります。

- カメラ画像の全黒・全白・固定パターン（レンズキャップ、配線断線など）。
- LiDAR 点群の突然のスパース化や全消失。
- Radar のレンジ・速度分布の異常。
- ログファイルの書き込み失敗やストレージフル。

これらの異常を検知した場合、車両側でアラートを出すだけでなく、クラウド側にテレメトリとして送信し、該当区間のデータを学習データセットから除外する、もしくは別途ラベル付けするなどの対応が考えられます。

故障検知ロジックは、単純なルールベースから統計モデル・機械学習ベースまで様々です。例えば、

- 一定時間連続で全黒画像が続いた場合に「カメラ故障疑い」と判定する単純なしきい値ベース。
- 正常稼働時の画素値分布や点群密度分布を学習しておき、KL ダイバージェンスなどの指標で異常を検知する統計ベース。
- 正常時ログを教師として学習した自己教師ありモデルにより、再構成誤差などから異常を検知する機械学習ベース。

どの方式を採用するにせよ、検知結果を「どのレベルの確信度を持つか」「運転継続可否に関わるか」「データ活用に関わるか」で分類し、車両上の動作（フェイルセーフ・警告表示）とデータ基盤側の動作（ログタグ付け・除外）に反映する設計が重要です。

## リアルタイム統計（露出・ノイズ・パケットドロップ）

センサーが完全に故障していなくても、露出設定の偏りやノイズ増大、ネットワークパケットドロップなどにより、データ品質が徐々に低下していくことがあります。これらを早期に検知するために、オンボードで簡易な統計量を継続的に計算し、しきい値を超えた場合にフラグを立てる仕組みが有効です。

例えば、以下のような指標が考えられます。

- カメラ画素値のヒストグラムや平均・分散。
- LiDAR 反射強度の分布や有効点数。
- 通信パケットのロス率や遅延分布。

データ中心・Closed-Loop の観点では、これらの統計値をフリート全体で収集・可視化することで、センサー構成やカメラチューニングの改善、ハードウェアリビジョンの見直しなどに役立てることができます。

### ダッシュボードとしきい値の継続的チューニング

リアルタイム統計は、それ単体では意味を持ちにくく、フリート全体の傾向と比較して初めて有用な情報になります。例えば、

- カメラ露出の平均・分散が、同一 ODD・同一車両世代の平均からどれだけ逸脱しているか。
- LiDAR の有効点数が、特定ロケーションや天候で一様に低下していないか。
- ネットワークパケットロス率が、特定 ECU 世代や車両ロールで高くなっていないか。

といった観点で、フリート全体のダッシュボードを構築し、しきい値のチューニングやハードウェアリビジョンの改善に役立てます。このとき、「データ品質指標の異常」と「モデル性能・インシデント率の悪化」がどの程度相関しているかを分析することで、「どの指標を重視すべきか」も見えてきます。

## データ品質情報と学習・評価の連携

オンボードで計測したデータ品質情報は、単なる監視用途にとどまらず、学習・評価パイプラインに組み込むことが重要です。例えば、以下のような活用方法が考えられます。

- データ品質フラグに基づいて、学習データセットから問題あるサンプルをフィルタリングする。
- 品質指標を特徴量としてモデルに入力し、悪条件下でのロバスト性を向上させる。
- モデル性能とデータ品質指標の相関を分析し、どの品質指標が安全性に影響しているかを特定する。

Closed-Loop の観点では、データ品質の測定 → モデル性能との関係分析 → センサー構成やチューニングの見直し → 再データ収集というループを継続的に回すことで、フリート全体の「データの健康状態」を改善していくことができます。

### 品質ラベル付きデータセットの構築

データ品質情報をうまく活用するためには、品質ラベル付きのデータセットを構築することが有効です。例えば、

- 正常: 品質指標が許容範囲内のサンプル。
- 軽度異常: 露出やノイズがやや悪いが、ラベル付けや学習にはまだ耐えうるサンプル。
- 重度異常: センサー故障や大きなタイムスタンプ不整合があり、学習・評価には使うべきでないサンプル。

といったラベルを付与し、それぞれのカテゴリに対するモデル性能を測定することで、「どの程度の品質劣化までなら実用上許容できるか」を定量的に把握できます。また、軽度異常データを含めた学習と含めない学習を比較することで、モデルのロバスト性と性能のトレードオフも評価できます。

### 品質指標を用いたデータ選択・難例発見

第 4 章で扱うデータ選択・アクティブラーニングの文脈では、データ品質指標を用いて「難例」を発見することも可能です。例えば、

- 品質指標は正常だが、モデルの不確実性が高い・エラーが多いサンプルは、「モデル側の課題」を示します。
- 品質指標が悪く、モデルのエラーも多いサンプルは、「センサー構成・チューニング側の課題」を示します。

このように、品質指標とモデル挙動を組み合わせた分析により、Closed-Loop の「どこを改善すべきか」をより精緻に切り分けることができます。

