# 1.5 Closed-Loop データエンジンの 7 段階

この節では、本書の中核となる Closed-Loop データエンジンを 7 つの段階に分解し、それぞれがどのような役割を持つかを俯瞰します。各段階の詳細な実装や設計指針は、第 2 章以降で詳しく解説しますが、ここでは「なぜその段階が必要なのか」「どのように前後の段階とつながるのか」を理解することを目的とします。データ中心・Closed-Loop の観点から、自社・自チームの現状をどの段階で止めているのか、どこを強化すべきかを考えるためのフレームワークとしても活用できます。

7 段階のうち、(I)〜(IV) は主に「データ供給側」のプロセス、(V)〜(VII) は「モデルとシステム評価・展開側」のプロセスと捉えることができます。しかし実際には、(V) のエラー分析結果が (III)(IV) に直結したり、(VII) のインシデントが (I)〜(IV) 全体にフィードバックされたりと、多数のループが重なっています。本節では、各段階の役割と代表的なインターフェースを整理しつつ、「どの段階の改善がどのようなインパクトを持つか」を俯瞰的に説明します。

## (I) データ収集

第 1 段階は、実世界およびシミュレーションからのデータ収集です。本書の第 2 章で詳述します。ここでは、ODD (operational design domain) の定義、フリート構成、センサー構成、エッジトリガー設計などが主要なテーマになります。

データ中心・Closed-Loop の観点では、単に「たくさん集める」ことよりも、「どのようなシーンをどれくらいのバランスで集めるか」「オンラインモニタリングの結果を収集ポリシーにどう反映するか」が重要です。ロングテール事象や安全クリティカルなシナリオを意識的に収集できるかどうかが、後続の段階の効率と上限性能を大きく左右します。

この段階で意識すべき代表的な質問として、次のようなものがあります。

- 自分たちの ODD に対して、どの地域・どの時間帯・どの天候の走行が不足しているか。
- どの種類のインシデントや介入を「収集トリガ」として定義し、その前後のログをどの程度の長さで保存しているか。
- FOT 車両・量産車両・社内実験車両など、車両ロールごとにどのような収集ポリシーの違いを持たせているか。

これらの質問に答えられる状態は、「データ収集が暗黙知ではなく設計されている」状態と言い換えられます。第 2 章では、これらをより体系的な設計指針として掘り下げます。

## (II) データ保存・インジェスト

第 2 段階は、収集したデータを安全かつ検索しやすい形で保存し、解析・学習に使える形式にインジェストするフェーズです。本書の第 3 章が対応します。データレイクの設計、ストレージ階層 (ホット／コールド)、圧縮・サンプリング戦略、インデックス・メタデータ管理などが主要トピックになります。

Closed-Loop の観点からは、「あとから必要になったときに、どのような切り口でデータにアクセスできるか」が重要です。例えば、「雨天夜間の交差点右折シーン」「特定バージョンのモデルが介入を多発させた区間」などのクエリに素早く応答できるインジェストとカタログ設計が求められます。

この段階での失敗パターンとしてありがちなのは、「データはあるが、誰もどこに何があるか分からない」「同じようなログが複数のストレージに重複している」といった状態です。これは、後続の (III)〜(V) の効率を著しく下げるだけでなく、インシデント調査や規制対応の観点でも大きなリスクになります。データ中心・Closed-Loop のフレームワークでは、(II) の成熟度を測る指標として、例えば以下のようなものを設定することが考えられます。

- 代表的なクエリに対して、必要なログを取得するまでの時間（人手・計算の両方）。
- 同一 Drive / Scene が重複して保存されている割合。
- データセットを構成する Drive / Scene の集合をメタデータレベルで再構成できるかどうか。

## (III) データ選択・前処理・データセット設計

第 3 段階は、データレイクから学習・評価に用いるデータセットを選択し、前処理やフィルタリングを行うフェーズです。本書の第 4 章が対応します。サンプリング戦略、バランシング、データクリーニング、特徴量抽出、データオーグメンテーションなどが中心テーマです。

データ中心アプローチでは、この段階が最も「工学的工夫の余地が大きい」部分のひとつです。モデルのエラー分析結果をもとに、どのようなシーンを追加・削減するか、どのようなメトリクスでデータセットのカバレッジを評価するか、といった意思決定が Closed-Loop の質を左右します。

実務では、「データ選択と前処理」が単なる前処理スクリプトではなく、明確なポリシーと指標を持つプロセスとして運用されているかどうかが重要です。例えば、次のような問いに答えられるかどうかが、(III) の成熟度の目安になります。

- 現行の学習データセットにおいて、ODD セグメントごとのサンプル数・走行時間はどのような分布になっているか。
- Long-tail セットや評価専用セットは明示的に定義されているか、それとも「なんとなく選んだ難しいシーン」の寄せ集めになっていないか。
- 前処理やデータオーグメンテーションのバージョンが、モデルバージョンやデータセットバージョンと明確に紐付いているか。

第 4 章では、これらの質問に答えられるようなメトリクスやパイプライン設計を具体的に紹介します。

## (IV) データラベリング・オートラベリング

第 4 段階は、データに付与するラベルの設計と付与プロセスです。本書の第 5 章が対応します。ラベルスキーマ設計、アノテーションツール、品質管理、アクティブラーニング、オートラベリング、ラベル監査などが主要トピックになります。

自動運転ではラベリングコストが極めて高いため、「どのサンプルに人手ラベルを投資するか」「どこまでをオートラベリングで代替するか」といった戦略が重要です。Closed-Loop の観点では、オンラインモニタリングやシミュレーションから得られた失敗シーンを、いかに優先度高くラベリングキューに投入するかがポイントになります。

ラベルは、モデルの「教師」であると同時に、組織としての世界の見方を定義するものでもあります。ラベルスキーマの曖昧さや一貫性の欠如は、どれだけモデルを改良しても性能が頭打ちになってしまう根本原因になりがちです。データ中心・Closed-Loop のフレームワークでは、(IV) を単なる下流の後処理ではなく、「Closed-Loop の中核にあるナレッジベース」と捉えます。

例えば、オンラインモニタリングで新しいパターンのインシデントが検出された場合、そのパターンが既存タクソノミの中でどのように表現されるべきか、あるいは新たなラベルカテゴリを追加すべきか、といった議論が必ず発生します。この議論自体が、Closed-Loop データエンジンにおける重要なフィードバックプロセスです。

## (V) モデル学習・オフライン評価

第 5 段階は、実際にモデルを学習し、オフラインで評価するフェーズです。本書の第 6 章が対応します。学習レシピ設計、ハイパーパラメータ探索、分散学習、モデル選択、オフラインメトリクス設計などが中心となります。

データ中心・Closed-Loop の観点では、モデル学習そのもの以上に、「どのデータセット構成・どの評価指標で性能を測るか」「どのようなエラー分析を行い、次のデータ選択・ラベリングにフィードバックするか」が重要です。オフライン評価で得られた知見が、そのまま次の (III)(IV) 段階への入力となります。

ここで重要なのは、「(V) の出口が (III)(IV) の入り口になっているかどうか」です。単に「新しいモデルを学習してベンチマークスコアを報告する」だけでは、Closed-Loop にはなりません。エラー分析レポートや ODD／シナリオ別の性能指標を通じて、

- どの ODD・どのシナリオで性能が不足しているか。
- それがデータ不足・ラベル品質・モデルアーキテクチャのどれに起因しているか。

を明らかにし、(III)(IV) のデータ選択・ラベリング戦略に反映させることが重要です。このループが確立している組織では、モデルアーキテクチャの刷新よりも、データセット設計とラベルポリシーの改善が性能向上の主たるドライバーになっていることが多いです。

## (VI) シミュレーション / テスト検証（Closed-Loop 評価）

第 6 段階は、シミュレーションや再生テストを用いた Closed-Loop 評価のフェーズです。本書の第 7 章が対応します。シナリオベーステスト、Monte Carlo テスト、デジタルツイン、HiL/SiL 環境、テスト評価指標などが主要テーマです。

ここでは、モデルをスタックの一部または全体に組み込み、時間発展を伴う Closed-Loop な環境で挙動を評価します。単一フレームの認識精度だけでなく、「連続した意思決定の結果としての安全性・快適性・効率性」を評価できる点が特徴です。シミュレーションで検出された弱点シナリオは、再び (I)〜(IV) の段階にフィードバックされます。

シミュレーション / テスト検証の段階では、「評価用データセット」ではなく「評価用シナリオ」が主役になります。これは、(III)(V) で扱うデータセットレベルの評価とは考え方が異なります。例えば、次のような観点が重要になります。

- ODD と機能ごとに、どれだけ多様なシナリオがテストされているか（カバレッジ指標）。
- 同じシナリオに対して、モデルバージョン間で挙動がどう変化したか（リグレッション検知）。
- 実世界で観測されたインシデントが、シミュレーション上でどの程度再現・拡張されているか。

第 7 章では、これらを支えるシミュレーション基盤とシナリオ DB の設計を詳しく説明しますが、本節の文脈では、「(VI) の結果が (I)〜(IV) のデータパイプラインにどのように戻っていくか」を意識しておくことが重要です。

## (VII) 実世界展開・オンライン評価・フィードバック

第 7 段階は、モデルを実世界に展開し、オンラインで挙動を監視しながらフィードバックを得るフェーズです。本書の第 8 章が対応します。OTA 配信、オンラインモニタリング、テレメトリ収集、A/B テスト、セーフティゲート、ヒヤリハット分析などが主要トピックです。

Closed-Loop データエンジンの観点では、この段階がサイクルの「入り口」と「出口」を兼ねています。実世界で観測された事象が (I) の収集ポリシー、(III) のデータセット設計、(IV) のラベリング戦略にどのように反映されるかが、改善速度と安全性の両立に直結します。

## 7 段階フレームワークの使い方

この 7 段階は、必ずしも直線的に一方向に進むものではなく、多数のフィードバックループで相互に接続されています。例えば、シミュレーション (VI) の結果から直接データ収集戦略 (I) を変更することもあれば、オンライン評価 (VII) の結果をもとにラベルスキーマ (IV) を見直すこともあります。

読者のみなさんには、自身の組織やプロジェクトにおいて、どの段階がすでに整備されており、どの段階がボトルネックになっているのかをこのフレームワークを用いて点検していただきたいです。本書の各章を読み進める際には、「自分たちの Closed-Loop はどこまで閉じているのか」「どこから強化すべきか」を意識しながら、具体的な設計・運用のアイデアを拾っていただければと思います。

実務でこのフレームワークを適用する際には、例えば次のような簡単なセルフアセスメントを行うことが考えられます。

- (I)〜(VII) の各段階について、「プロセスが定義されているか」「指標が定義されているか」「改善サイクルが存在するか」の 3 軸で 0〜2 点などのスコアを付ける。
- 合計点や段階ごとのスコアを比較し、「現状では (III)(IV) が弱い」「(V) でのエラー分析が (I)〜(IV) に十分戻っていない」といったギャップを可視化する。
- 次の四半期やプロジェクトフェーズで、どの段階のスコア向上を目標にするかをチームで合意する。

このように、7 段階フレームワークは単なる概念図ではなく、組織の現状を定期的に棚卸しし、どこに投資すべきかを議論するための共通言語として活用できます。本書の残りの章では、それぞれの段階で何をすればスコアが上がるのかを、より具体的な技術とプロセスの観点から示していきます。

最後に、本節で示した 7 段階を、これまでの 1 章の議論と結びつけておきます。1.1 ではモデル中心からデータ中心へのパラダイム転換、1.2 では自動運転スタックの構造、1.3 では世界的なデータ中心トレンド、1.4 では DataOps / MLOps アーキテクチャの俯瞰を行いました。1.5 の 7 段階フレームワークは、これらを統合する「座標系」として機能します。

- 1.1 で述べたロングテール問題は、(I)〜(IV) の設計が不十分なまま (V) のモデル改良に注力してしまうと解決しにくい、という形で現れます。
- 1.2 のスタック構造は、各段階でどのモジュール・どのシグナルが関わるかを理解するためのマップです。
- 1.3 のトレンド（世界モデル、自然言語インターフェース、シミュレーションなど）は、7 段階の各所に挿さる「高度なコンポーネント」として捉えられます。
- 1.4 の DataOps / MLOps アーキテクチャは、7 段階を技術的に実現するためのパイプラインや基盤そのものです。

第 2 章以降では、この 7 段階を一つひとつ詳細に分解しながら、「具体的にどのような設計・運用を行えば、データ中心・Closed-Loop な自動運転モデル開発が実現できるのか」を掘り下げていきます。

