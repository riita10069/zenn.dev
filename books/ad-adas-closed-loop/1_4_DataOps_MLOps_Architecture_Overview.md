---
title: "1.4 自動運転 DataOps / MLOps アーキテクチャの俯瞰"
---

# 1.4 自動運転 DataOps / MLOps アーキテクチャの俯瞰

この節では、自動運転システムに特有の DataOps / MLOps アーキテクチャを俯瞰します。データレイクやデータカタログ、GPU クラスタ、シミュレーション基盤、OTA (over-the-air) 更新、オンラインモニタリングといったコンポーネントがどのようにつながり、Closed-Loop なデータエンジンを支えているかを説明します。また、車両側 (オンボード) とクラウド側の役割分担、実験管理・モデルレジストリ・CI/CD・監査ログの関係を整理し、本書で後に詳しく扱う各要素の全体像を示します。

## オンボードとクラウドの役割分担

自動運転システムは、計算資源やネットワーク制約、レイテンシ要求、安全性要件などを踏まえ、車両側 (オンボード) とクラウド側の役割を明確に分担する必要があります。一般的には、以下のような切り分けがなされます。

- オンボード:
  - リアルタイム推論 (online inference) と車両制御。
  - センサデータの一時バッファリング、イベントトリガー判定。
  - 低レートのテレメトリ送信およびアップロード候補データの選別。
- クラウド:
  - 大規模なデータ保存・検索・加工 (DataOps)。
  - モデル学習・ハイパーパラメータ探索・評価 (MLOps)。
  - シミュレーション基盤やデジタルツイン環境の運用。
  - モデル配信・コンフィグ配信・フリートマネジメント。

Closed-Loop なデータエンジンを成立させるためには、オンボードで取得したフィードバックシグナル（運転者介入、システム警告、自己診断結果など）が、遅延許容な形でクラウドに集約され、データ選択・ラベリング・モデル更新に反映される仕組みが重要です。

### レイテンシと安全クリティカル度による役割分担

実務では、上記のような大まかな役割分担をさらに細かく、「レイテンシ要求」と「安全クリティカル度」に応じて整理することが多いです。

- 数十ミリ秒オーダーのレイテンシが要求される安全クリティカルな制御（車両安定化、衝突回避など）は、原則としてオンボードで完結させます。
- 数秒〜数分程度の遅延が許容される分析・モニタリング・ログアップロードなどは、クラウドとの連携を前提とします。
- 中間的なもの（例: クラウドからのフリート設定変更、トリガポリシー更新など）は、フェイルセーフを確保したうえで OTA を用いて反映します。

DataOps / MLOps の観点からは、「どのシグナルがクラウド側の Closed-Loop を駆動するトリガになるか」「どの量のデータをどの時間スケールでクラウドに集約すべきか」を、レイテンシと安全クリティカル度を踏まえて設計することが重要です。

### オンボードロギングとクラウドインジェストの境界

第 2〜3 章で詳しく扱うように、オンボードでどこまでログを前処理・圧縮し、どこからクラウド側のインジェストパイプラインに引き渡すかは、DataOps / MLOps アーキテクチャに大きな影響を与えます。例えば、以下のような選択肢があります。

- オンボードで生センサデータをそのままリングバッファに保持し、イベント発生時のみ前後数十秒をまとめてアップロードする。
- オンボードで軽量な特徴抽出やオートラベリングを行い、クラウド側では特徴ベースの学習・評価を中心にする。
- オンボードで中間表現（例: BEV 特徴マップや検出結果）をログとして保存し、クラウド側で詳細な再処理・評価に利用する。

どの戦略を採用するにしても、オンボードとクラウドの境界は「ログスキーマの境界」でもあります。データ中心・Closed-Loop の観点では、この境界を曖昧にせず、「オンボードで保証されるデータ構造」と「クラウドでの正規化スキーマ」を明確にドキュメント化しておくことが重要です。

## データレイクとデータカタログ

大規模な自動運転フリートでは、日々 TB〜PB 単位のログデータが生成されます。これらを扱うために、多くの組織はオブジェクトストレージを中心としたデータレイク (data lake) を構築します。データレイクには、センサ生データ、圧縮・サンプリング済みデータ、派生特徴量、評価結果、シミュレーションログなど、さまざまな形式のデータが格納されます。

しかし、単にストレージにファイルを置くだけでは、目的のシーンやデータセットを効率的に見つけることはできません。そのため、データカタログ (data catalog) やメタデータ管理システムが重要になります。データカタログは、各ログファイルやサンプルに対して以下のような属性を付与し、検索・絞り込みを可能にします。

- 収集日時・場所・天候・時間帯・道路種別などのコンテキスト情報。
- ODD、テストキャンペーン、シナリオタグなどのビジネスメタデータ。
- ラベリング状況、使用済みデータセット、評価結果との関連付け。

データ中心・Closed-Loop の観点からは、「どのようなクエリでどのデータを容易に取り出せるか」が開発速度と品質に直結します。特に、モデルの弱点に対応するロングテール事象を素早く検索し、ラベリングキューに投入できるかどうかが重要です。

### メタデータ主導のクエリ設計

データレイクとカタログ設計の成否は、「現場のエンジニアやアナリストがどのようなクエリを投げたいか」をどれだけ正確に捉えているかで決まることが多いです。典型的なクエリ例として、次のようなものがあります。

- ODD ベース: 「都市高速 × 夜間 × 雨 × 交差点右折」のシーンを抽出したい。
- モデル挙動ベース: 「最新バージョンで介入が多発した区間のログをすべて取得したい」。
- イベントベース: 「AEB 作動が発生したシーンのうち、歩行者が近かったものだけを抽出したい」。

こうしたクエリを効率的に実現するためには、Drive / Scene / Frame 単位のテーブル設計と、属性メタデータの整備が不可欠です。第 3・4 章では、これらをどのようなスキーマ・インデックスで表現するかを詳しく見ていきます。

### カタログと権限管理の統合

大規模組織では、データカタログは単に「どこに何があるか」の辞書ではなく、「誰がどのデータにアクセスできるか」を制御するためのインターフェースにもなります。例えば、以下のような機能が統合されます。

- プロジェクト・ロールごとのアクセス権限（RBAC/ABAC）をカタログのレベルで定義する。
- 高機密データ（顔・ナンバープレート・特定顧客データなど）については、匿名化済み派生データのみをカタログに表示する。
- データセットの「ステータス」（実験用・本番用・廃止予定など）をカタログで管理し、誤用を防ぐ。

データ中心・Closed-Loop の観点では、「必要な人が必要なデータにすぐアクセスできる」ことと「不要な人が機密データにアクセスできない」ことを両立させる必要があります。そのため、カタログ設計時点でガバナンス要件を織り込んでおくことが重要です。

## GPU クラスタと学習・評価パイプライン

自動運転モデルは、画像・点群・時系列など高次元データを扱うため、大規模な GPU クラスタや専用アクセラレータが不可欠です。MLOps の観点では、これらの計算資源を効率的に共有し、再現性の高い学習・評価ジョブを継続的に実行できる仕組みが求められます。

典型的には、以下のような要素が組み合わされます。

- コンテナ化された学習・評価イメージ (Docker など)。
- ジョブスケジューラ (Kubernetes, Slurm 等) によるリソース管理。
- 学習スクリプト・コンフィグ・データセットのバージョン管理。
- メトリクス・ログ・モデルチェックポイントの自動保存。

Closed-Loop データエンジンでは、「新しいデータセット定義 → 学習ジョブ実行 → オフライン評価 → シミュレーション評価」という一連の流れを、できるだけ自動化し、複数の実験を高速に回せることが重要です。そのために、パイプライン定義ツールやワークフローエンジン (例: Airflow, Kubeflow Pipelines など) が活用されることが多いです。


## シミュレーション基盤とデジタルツイン

シミュレーション基盤 (simulation platform) は、Closed-Loop 評価とデータ拡張の両面で重要な役割を担います。高精度な物理モデルと交通エージェントモデルを持つシミュレータ上で、実世界で収集したシナリオを再現・変形し、モデルの挙動を安全に評価することができます。

近年では、実世界のマップ・センサーモデル・交通統計に基づいたデジタルツイン (digital twin) 環境を構築し、オンライン運用中のフリートと連携させる取り組みも増えています。例えば、実運用で検出されたヒヤリハット事象をデジタルツイン上で再現し、さまざまなバリエーション（天候や交通密度、相手車両の挙動変更など）を生成して評価する、といった Closed-Loop が考えられます。

### シミュレーションとデータレイクの接続

DataOps / MLOps アーキテクチャの観点からは、「シミュレーション基盤がデータレイクとどのようにつながっているか」が重要です。典型的には、以下のような接続パターンがあります。

- ログリプレイ: 実世界の Drive / Scene をシミュレータにインポートし、センサモデルと物理モデルを通じて再生する。
- シナリオ生成: データレイクに蓄積されたシーンや統計（交通密度、車種分布など）をもとに、新しいシミュレーションシナリオを生成する。
- 結果のフィードバック: シミュレーション実行結果（成功・失敗フラグ、メトリクス）をデータレイクに保存し、評価レポートや Long-tail セットに統合する。

第 7 章では、これらの処理を支える API 設計やシナリオ DB の構造について詳しく扱いますが、本節では「シミュレーションもデータエンジンの一部として扱う」という視点を押さえておいてください。

## OTA 更新とオンラインモニタリング

実世界に展開された車両へのモデル配信には、OTA (over-the-air) 更新が広く用いられます。OTA 基盤は、以下のような機能を含むことが多いです。

- モデルバージョンと構成の管理。
- 段階的ロールアウト (canary release, A/B テスト)。
- ロールバックメカニズムとフェイルセーフ設計。

同時に、オンラインモニタリング (online monitoring) とテレメトリ収集は、Closed-Loop の出発点として重要です。推論メトリクス、自己診断結果、運転者介入イベント、ログアップロード状況などを継続的に監視し、異常を検知した場合にはアラートや追加データ収集をトリガします。

### リリースゲートとサーバサイド評価

OTA 展開の前後では、サーバサイドで行われる評価とリリースゲート設計も重要です。典型的には、以下のようなステップが含まれます。

- オフライン評価: 第 6 章で扱うデータセットレベルのリグレッションテストを通過したモデルのみが OTA 候補となります。
- シミュレーション評価: 第 7 章で扱うシナリオベーステストや Closed-Loop SiL を通過したモデルのみが実車展開候補となります。
- 実車ステージング: 社内テスト車両や限定フリートでの A/B テストを行い、オンライン指標（介入率、インシデント率など）を観測します。

これらのステップと結果は、モデルレジストリや監査ログに記録され、後から「なぜこのモデルがリリースされたのか」「どの評価を通過しているのか」を説明できる状態にしておく必要があります。データ中心・Closed-Loop の観点では、OTA 自体も「評価結果と結びついたデータ駆動の意思決定プロセス」として設計されるべきです。

## 実験管理・モデルレジストリ・CI/CD・監査ログ

自動運転のような安全クリティカルな領域では、「いつ・誰が・どのデータと設定で・どのモデルを学習し・どの車両に展開したか」を追跡できることが重要です。そのために、以下のようなコンポーネントが DataOps / MLOps 基盤に組み込まれます。

- 実験管理ツール (experiment tracking): ハイパーパラメータ、使用データセット、コードバージョン、メトリクスを記録します。
- モデルレジストリ (model registry): モデルアーティファクトとメタデータ、承認ステータス、互換性情報などを管理します。
- CI/CD パイプライン: コード変更やデータセット変更に対して、自動テスト・ビルド・デプロイを行います。
- 監査ログ (audit log): モデル配信やコンフィグ変更、データアクセスなどの操作履歴を記録します。

これらの仕組みは、単に開発効率を高めるだけでなく、事故調査や規制対応、社内外の安全レビューにおいても不可欠です。データ中心・Closed-Loop の開発を行う際には、「改善サイクルの速さ」と「トレーサビリティ・説明可能性」を両立させるアーキテクチャ設計が求められます。

### 実験メタデータとデータセットバージョンの紐付け

実験管理ツールやモデルレジストリを導入しただけでは、DataOps / MLOps の価値は十分に発揮されません。特に重要なのは、「実験メタデータとデータセットバージョンをどの粒度で紐付けるか」を設計することです。

- 各実験に対して、「使用したデータセット ID」「適用したフィルタ条件（ODD、シナリオタグなど）」「ラベルスキーマバージョン」「前処理バージョン」などを明示的に記録する。
- モデルレジストリには、「どの実験から生まれたモデルか」「どの評価セットに対してどのスコアを達成したか」といった情報を紐付ける。
- 監査ログには、「誰がいつどのモデルをどの車両群に展開したか」「そのときの承認者は誰か」を残す。

データ中心・Closed-Loop の観点では、これらの仕組みがすべて「データセット」「シナリオ」「ODD セグメント」といったデータ側の概念と結び付いていることが重要です。そうすることで、インシデントや性能低下が発生した際に、「どのデータに問題があり、どのモデル・車両に影響しているか」を素早くトレースできるようになります。

## まとめ: DataOps / MLOps アーキテクチャと Closed-Loop データエンジン

本節では、自動運転向け DataOps / MLOps アーキテクチャの主要コンポーネント（オンボード／クラウド、データレイク／カタログ、GPU クラスタ、シミュレーション基盤、OTA・オンラインモニタリング、実験管理・モデルレジストリ・CI/CD・監査ログ）を俯瞰し、それぞれが Closed-Loop データエンジンのどの部分を支えているかを整理しました。

ここで示したアーキテクチャは、あくまで典型的な構成です。実際のプロジェクトでは、利用可能なリソースや既存システム、組織構造、規制要件などに応じて、多様なバリエーションが存在します。ただし、どのようなバリエーションであっても、

- データ収集から学習・評価・展開までの一連の流れが途切れずにつながっていること。
- 各ステップで生成されるデータとメタデータが、後からトレース可能な形で保存されていること。
- オンライン・オフラインの両方のフィードバックが、再びデータエンジンに戻るループが設計されていること。

という 3 つの条件を満たしているかどうかが、DataOps / MLOps アーキテクチャの健全性を評価するうえでの重要な観点になります。

第 2〜8 章では、本節で概観したアーキテクチャの各コンポーネントを、より具体的な実装と運用の観点から掘り下げていきます。読者のみなさんには、自身の組織やプロジェクトに照らして、「どの要素がすでに整備されており、どの要素がボトルネックになっているか」を意識しながら読み進めていただきたいです。

最後に、実務上の一つの目安として、本節で述べた要素を段階的に導入するステップ例を挙げておきます。

1. ログスキーマとデータレイクの整備（Drive / Scene / Frame 単位の構造化）。
2. 基本的なメタデータとカタログの導入（ODD・シナリオ・ソフトウェアバージョンなど）。
3. 単純なパイプライン as Code による学習・評価ジョブの自動化。
4. モデルレジストリと実験管理ツールの導入、およびデータセットバージョンとの紐付け。
5. シミュレーション基盤・シーン検索・Long-tail セットなど、高度な Closed-Loop を支えるコンポーネントの導入。

どのステップから始めるべきかは組織によって異なりますが、「データの流れを可視化する」「実験とデータセットの紐付けを明確にする」という 2 点は、規模の大小にかかわらず共通して有効な出発点であると考えられます。
