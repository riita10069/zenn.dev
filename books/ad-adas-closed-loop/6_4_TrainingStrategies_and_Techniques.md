---
title: "6.4 学習戦略とトレーニングテクニック"
---

# 6.4 学習戦略とトレーニングテクニック

この節では、学習戦略とトレーニングテクニックについて解説します。自己教師あり学習・事前学習・ファインチューニング、マルチタスク学習・カスケード／蒸留、Curriculum Learning・難例マイニングなどを整理し、データ中心・Closed-Loop の観点から「どのデータから学習を始め、どのデータで性能を押し上げるか」を考えます。

## 自己教師あり学習・事前学習・ファインチューニング

自動運転のフリートから得られるログの多くは、ラベル付けされていません。これらの膨大な未ラベルデータを活用するために、自己教師あり学習 (self-supervised learning) や表現学習 (representation learning) を先に行い、その後で少量のラベル付きデータでファインチューニングする戦略が有効です。

- 画像・動画向け: contrastive learning（SimCLR, MoCo 系）、masked image modeling、時系列予測（future frame prediction）など。
- 点群向け: masked point modeling、自己復元タスク、局所パッチレベルの contrastive learning など。
- シーケンス向け: BEV 特徴列に対する masked token prediction、将来 occupancy の予測など。

事前学習の目的は、ODD 全体にわたる多様なシーンから汎用的な表現を学習し、その上にタスク固有のヘッド（検出・予測・プランニングなど）を乗せることです。Closed-Loop の観点では、「新しい ODD や環境条件が追加されたときに、事前学習済み表現をどのように拡張・再利用するか」が重要になります。例えば、新地域展開時には、その地域の未ラベルデータで追加の自己教師あり学習を行い、その後限定的なラベル付きデータでファインチューニングする、といった運用が考えられます。

## マルチタスク学習とカスケード・蒸留

マルチタスク学習 (multi-task learning) は、1 つのバックボーンから複数のタスク（検出・セマンティックセグメンテーション・車線検出・ドライブアビリティ推定など）を同時に学習するアプローチです。特徴共有により、データ効率や推論効率が向上することが期待されます。一方で、タスク間の競合や損失のバランス調整が難しいことも知られています。

- 損失の重み付け: 固定の重み付けではなく、不確実性や勾配ノルムに基づいて自動的に重みを調整する手法が提案されています。
- カスケード構成: あるタスクの出力（例: 高精度だが遅いモデルの出力）を別モデルの教師信号として利用したり、難例のみを詳細モデルで再処理する構成もあります。
- 知識蒸留 (knowledge distillation): 大規模な教師モデルから、小型の生産向けモデルへ知識を移すことで、精度とレイテンシのバランスを取ります。

データ中心の観点では、マルチタスク構成にすることで、同じシーンに対して複数タスクのラベルを揃える必要が生じます。ラベルポリシーやアノテーションコストを踏まえて、「どのタスクを同時に学習するか」「どのタスクは蒸留や pseudo-labeling で代替するか」を決めることが重要です。

## Curriculum Learning と難例マイニング

Curriculum Learning（カリキュラム学習）は、モデルに対して「簡単な例から徐々に難しい例へ」と段階的に学習させる戦略です。自動運転では、例えば以下のようなカリキュラムが考えられます。

- ステージ 1: 白昼・晴天・単純な道路環境（単路・信号なし交差点など）で学習。
- ステージ 2: 夜間・雨天・複雑な交差点・工事区間など難度の高いシーンを追加。
- ステージ 3: インシデントやヒヤリハットに関連する極端なケース、レアな長尾シナリオを重点的に学習。

難例マイニング (hard example mining) では、モデルが誤分類したサンプルや、損失が高いサンプルを次の学習サイクルで優先的にサンプリングします。これは第 4 章で述べた active learning や error mining と密接に関係しており、Closed-Loop の中で自然に組み込まれます。

- オフライン難例マイニング: 評価データセットやログリプレイの結果から、誤検出・見落とし・不安定挙動のシーンを抽出し、次回のデータセットに加える。
- オンライン難例マイニング: トレーニング中に損失上位のサンプルを記録し、次の epoch でサンプリング確率を高める。

これらの戦略を適用する際には、難例のみに過剰に集中して分布が偏りすぎないように、ベースラインとなるランダムサンプルとのバランスを取ることが重要です。

## データ不均衡・長尾分布への対処

自動運転のデータは、日常的なシーンが圧倒的多数を占める一方で、インシデントや危険シナリオは非常に稀です。この長尾分布に対処するために、以下のような戦略が用いられます。

- クラス重み付け・フォーカルロス (focal loss) による希少クラスの強調。
- データ拡張や合成データ生成により、希少シナリオのバリエーションを増やす。
- ロジックベースのルールと組み合わせ、モデル単独で難しい極端ケースに対してフォールバックルールを用意する。

Closed-Loop の観点では、フィールドから収集されたインシデントやヒヤリハットを継続的に取り込み、長尾部分の分布を動的に更新することが重要です。その際、単に希少シーンを増やすだけでなく、全体分布とのバランスを保ちつつ学習させることが求められます。

## オプティマイザ・スケジューラ・正則化テクニック

学習戦略には、オプティマイザや学習率スケジューラ、正則化テクニックの設計も含まれます。自動運転向けモデルは大規模であり、かつ長時間学習を行うため、安定性と収束性が特に重要です。

- オプティマイザ: AdamW や LAMB、AdaFactor など、大バッチ学習に適した手法がよく用いられます。
- 学習率スケジューラ: warmup 付き cosine decay や multi-step decay などを用い、初期学習の安定化と後半の微調整を両立します。
- 正則化: Weight decay、Dropout、Stochastic Depth、ラベルスムージングなどを組み合わせ、過学習を防ぎます。

また、mixed precision training (FP16 / BF16) や gradient checkpointing などのテクニックを用いることで、GPU メモリ効率とスループットを向上させることができます。これらは第 6.5 節で扱う分散学習設計とも密接に関連します。

## Closed-Loop における学習戦略の位置づけ

ここまで述べた学習戦略は、Closed-Loop 全体の中では「どのタイミングでどのデータをどのような方法で学習に投入するか」という設計に対応します。具体的には、以下のようなパターンが考えられます。

- 定期再学習: 一定期間ごとに、最新フリートデータからサンプリングしたデータセットで再学習を行い、分布ドリフトに追従する。
- イベント駆動再学習: インシデントや特定機能の性能悪化が検知されたときに、その ODD セグメントに特化したデータで集中的に再学習する。
- シミュレーション駆動再学習: 第 7 章で述べるシミュレーション環境で見つかった弱点シナリオを合成・拡張し、そのシナリオ群で追加学習を行う。

このような Closed-Loop 戦略を支えるためには、学習コードや設定がパイプライン化されており（第 6.7 節）、様々なデータサブセット・学習戦略を迅速に試せることが重要になります。
