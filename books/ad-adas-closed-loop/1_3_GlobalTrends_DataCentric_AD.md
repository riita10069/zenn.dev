# 1.3 データ中心自動運転モデルのグローバルトレンド

この節では、世界の自動運転・高度運転支援 (AD/ADAS) 開発におけるデータ中心 (data-centric) な潮流を俯瞰します。大規模フリートからのデータ駆動開発、世界モデル (world model) や BEV 表現、Foundation Model の台頭、自然言語クエリを用いた評価やデータ検索、自己教師あり学習や合成データの活用など、近年の代表的なトレンドを整理します。あわせて、それらが Closed-Loop なデータエンジンの設計にどのような影響を与えているかを考察します。

## 大規模フリートとデータ駆動開発

グローバルでは、数万〜数十万台規模のコネクテッド車両やロボタクシーフリートからデータを収集し、クラウド上のデータレイクに蓄積するアーキテクチャが一般的になりつつあります。車両からアップロードされるのは、生センサデータそのものだけでなく、オンボードでの簡易推論結果やイベントトリガー情報、メタデータ（天候・時間帯・位置情報など）を含むことが多いです。

このようなフリートベースのデータ駆動開発では、以下のような Closed-Loop が回っています。

- 実運用中の介入 (takeover) やヒヤリハット事象を検出し、その周辺のログを高優先度でアップロードする。
- オンラインモニタリングで検出された分布外 (out-of-distribution) シーンを、クラウド側で自動クラスタリングし、ラベリングキューに投入する。
- オフライン評価の結果をもとに、「どの ODD (operational design domain)・どの天候・どの時間帯のデータが不足しているか」を可視化し、フリートの走行計画やシナリオ収集ポリシーにフィードバックする。

重要なのは、データ収集が単なる「ログを全て保存する」行為ではなく、モデルの弱点やビジネス要件に基づいて設計された戦略的な活動になっている点です。フリートの規模が大きくなるほど、データ選別・優先度付け・プライバシー保護・通信コスト制約などを含めた DataOps の重要性が増していきます。

### フリート運用 × DataOps の実務パターン

大規模フリートを運用する組織では、データ駆動開発は次のような実務パターンとして定着しつつあります。

1. 常時計測とイベントトリガを組み合わせたログ収集  
   量産車両やサービス車両からは、位置・速度・介入フラグなどの低レートテレメトリが常時送信されます。同時に、AEB 作動・急ブレーキ・ステアリング介入・システム警告などのイベントが発生すると、その前後の高解像度センサログが優先度高くアップロードされます。
2. オンラインモニタリングと自動アラート  
   クラウド側では、介入率・近接オブジェクト件数・モデル信頼度統計などの指標をストリーミング集計し、閾値や統計モデルに基づいてアラートを発火します。アラートには、対象 ODD・ソフトウェアバージョン・車両世代などのメタデータが紐付きます。
3. インシデントレビューとシーン抽出  
   安全チーム・AD 開発チームがアラートに紐づくログをレビューし、代表的なシーンをシナリオ DB に登録します。この際、「夜間・雨・交差点右折・歩行者横断」といったシナリオタグを付与し、Long-tail セットの一部として管理します。
4. データセット更新とモデル再学習  
   抽出されたシーンは優先ラベリングキューで処理され、新たなデータセットバージョンに組み込まれます。その後、モデル再学習・オフライン評価・シミュレーション評価・リリースゲートを経て、新バージョンモデルが OTA でフリートに展開されます。

このようなループを継続的に回すには、フリート運用チームと DataOps / MLOps チームが密に連携し、オンライン指標とオフラインデータセットを一元的に管理できる基盤が不可欠です。第 2〜4 章・第 8 章では、このフリート × DataOps の具体的なアーキテクチャを詳しく説明します。

こうしたイベント統計は、実務ではテレメトリログから集計されます。例えば、ODD セグメントごとの走行距離とヒヤリハット件数から「1,000 km あたりのインシデント率」を算出し、優先的に対策すべき ODD を特定します。

```python
grouped = df.groupby("odd_segment").agg(
    total_distance_km=("distance_km", "sum"),
    total_incidents=("num_incidents", "sum"),
)
grouped["incidents_per_1k_km"] = (
    grouped["total_incidents"] / grouped["total_distance_km"].clip(lower=1e-3)
) * 1000.0
```

このような統計を継続的にモニタリングし、「どの ODD セグメントでインシデント率が高いか」「データ量に比して性能が悪い領域はどこか」を把握することが、データ中心・Closed-Loop な改善サイクルの出発点になります。

## 世界モデル・BEV 表現・Foundation Model の台頭

近年の研究では、世界モデル (world model) や BEV (bird's-eye view) 表現を用いて、周囲環境を統一的な表現空間にマッピングし、その上で知覚・予測・計画を統合的に処理するアーキテクチャが注目されています。これらは、いわば「自動運転版 Foundation Model」として、多数のタスクに転移可能な共通表現を学習しようとする試みです。

具体的には、以下のような方向性が活発です。

- 大規模なドライブレコーダログやシミュレーションデータを用いて、自己教師あり学習 (self-supervised learning) により BEV 特徴マップを事前学習する。
- マルチモーダル (multi-modal) なセンサー入力（カメラ + LiDAR + マップなど）を共通の世界座標系に投影し、時系列で一貫した 4D 表現として扱う。
- 事前学習した世界モデルを、物体検出、オキュパンシー予測、将来軌道予測、リスク推定など複数タスクにファインチューニングする。

このような Foundation Model のアプローチは、単一タスクごとにデータセットを独立管理する従来のスタイルから、「フリート全体のデータを統合的に活用する」方向へのシフトを促します。同時に、「どのデータを事前学習に使い、どのデータを下流タスクのファインチューニングに回すか」といったデータ分割戦略や評価プロトコルの設計が、新たな課題として浮上しています。

### Foundation Model 時代のデータ分割戦略

世界モデルや Foundation Model を前提とした場合、従来の「タスクごとに完全に独立したデータセット」という前提は成り立たなくなります。代わりに、次のようなレイヤ構造でデータを管理するパターンが一般的になりつつあります。

- 事前学習用コーパス (pre-training corpus)  
  フリート全体から収集された膨大な未ラベルデータや弱ラベル付きデータを統合し、自己教師あり学習や対比学習に用います。ここでは、ラベル精度よりも ODD カバレッジとシーン多様性が重視されます。
- タスク別ファインチューニングデータ  
  物体検出・オキュパンシー予測・将来軌道予測・リスク推定などのタスクごとに、高品質なラベルを持つサブセットを構成します。ラベリングポリシーの厳密さとロングテールカバレッジが重要です。
- 評価用ベンチマーク / シナリオセット  
  タスク横断で共通に利用される評価用データセットや、シナリオベーステスト用のセットを定義します。これらは頻繁に更新される事前学習コーパスとは切り離し、安定性とトレーサビリティを重視します。

データ中心・Closed-Loop の観点では、世界モデルの誤差パターンや不確実性を分析し、「どの ODD・どのシナリオで事前学習データが不足しているか」「どのタスクに追加のラベル投資を行うべきか」といった意思決定を行う必要があります。第 4〜6 章では、こうしたデータ分割戦略と評価プロトコルを、具体的なパイプライン例とともに紹介します。

## 自然言語クエリによるシーン検索・評価

大規模データレイクの時代には、「特定の条件を満たすシーンを素早く検索する」こと自体が重要な技術課題になります。最近では、自然言語 (natural language) クエリや大規模言語モデル (large language model; LLM) を用いて、シーン検索や評価を行う研究・実装が増えています。

例えば、以下のようなユースケースが考えられます。

- 「夜間かつ雨で、右折時に歩行者が横断しているシーンを抽出してほしい」といった自然言語条件を指定し、データレイクから該当ログを検索する。
- オンラインモニタリングで検出された異常挙動のログに対し、LLM がテキスト要約を行い、「どのようなシチュエーションで、何が起こったのか」を人間にとって読みやすい形で提示する。
- シミュレーションシナリオの自動生成や、テストケース仕様書のチェックに自然言語モデルを活用し、人間とのインタラクティブな要件定義を支援する。

このような自然言語インターフェースは、エンジニアだけでなく、テスト計画を担当する非エンジニアや安全チーム、プロダクトマネージャーなど、幅広いステークホルダーがデータにアクセスしやすくするための重要な手段になります。Closed-Loop の観点では、「何が問題だったのか」を人間が理解しやすい形で表現し、その理解をもとにデータ収集やラベリングポリシーを更新するサイクルを加速する役割を果たします。

### Embedding と組み合わせたハイブリッド検索

自然言語クエリは、メタデータやテキスト要約に基づく検索だけでなく、埋め込み (embedding) ベースの類似検索と組み合わせることで、より強力なデータ探索手段になります。典型的な構成は次のようになります。

1. センサデータ（画像・動画・BEV 特徴など）を世界モデルや自己教師ありモデルで埋め込みベクトルに変換し、ベクトルデータベースに格納する。
2. 自然言語クエリをテキストエンコーダや VLM で埋め込みに変換し、近傍検索により候補シーンを取得する。
3. 取得した候補シーンに対して、LLM による要約や追加タグ付けを行い、ラベリングキューやシナリオ DB に登録する。

Python でのごく簡単な疑似コードは、以下のようなイメージになります（実際のシステムでは専用のベクトルデータベースやインデックスライブラリを利用します）。

```python
import numpy as np

def cosine_sim(a, b):
    return (a @ b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8)

def top_k_similar(query_emb, db_embs, k=10):
    scores = [cosine_sim(query_emb, e) for e in db_embs]
    idx = np.argsort(scores)[::-1][:k]
    return idx, [scores[i] for i in idx]
```

実務では、Embedding 検索を DataOps 基盤に組み込むことで、「ある失敗シーンに類似するシーンを大量に収集する」「特定の自然言語条件を満たすシーンを即座に抽出する」といった Closed-Loop 改善が行いやすくなります。第 4 章では、Embedding ベースのシーン検索 UI やカタログ設計を詳しく扱います。

## 自己教師あり学習・シミュレーション・合成データの活用

自動運転では、すべてのセンサデータに高品質なアノテーションを付与することは現実的ではありません。そのため、自己教師あり学習 (self-supervised learning) や半教師あり学習 (semi-supervised learning)、教師なしドメイン適応 (unsupervised domain adaptation) など、ラベルの少ない設定で性能を引き出す技術が盛んに研究・実用化されています。

また、シミュレーション (simulation) や合成データ (synthetic data) の活用も重要な柱です。高精度なシミュレータを用いることで、現実世界ではなかなか遭遇しない危険シナリオを大量に生成し、モデルの堅牢性を評価・向上させることが可能になります。フォトリアリスティックなレンダリングや、実世界ログをベースにしたシナリオ再生・変形など、さまざまな方向性が探索されています。

データ中心・Closed-Loop の観点では、実世界データとシミュレーションデータの役割分担を明確にし、両者を一貫したパイプラインで扱うことが重要です。例えば、「実世界で観測されたロングテール事象をシミュレータで再現し、パラメータを変化させたバリエーションを生成する」「シミュレーションで検出された弱点シナリオを、実世界のデータ収集計画にフィードバックする」といったループが考えられます。

### 実世界データとシミュレーションのハイブリッド Closed-Loop

実世界データとシミュレーションデータの組み合わせ方にはさまざまなスタイルがありますが、データ中心の観点からは、次のようなハイブリッド Closed-Loop を構築することが多いです。

1. 実世界で発生したインシデントやヒヤリハットを検出し、その周辺のログを詳細に分析する。
2. 分析結果に基づいて、シミュレータ上で同様のシナリオを再現し、パラメータ（交通密度、相手車両挙動、天候など）を変化させたバリエーションを大量生成する。
3. 生成シナリオ上でモデルの挙動を Closed-Loop で評価し、失敗パターンを抽出する。
4. 失敗したシミュレーションシナリオの一部を「重要シナリオ」としてシナリオ DB に登録し、必要に応じて現実世界での追試（追加データ収集）を計画する。

このようなハイブリッドループにより、「実世界で 1 回しか観測されていない危険シナリオ」を、シミュレーション上では数千〜数万のバリエーションとして検証することが可能になります。第 7 章では、こうした Sim2Real / Real2Sim の橋渡しを含むシミュレーション基盤の詳細を扱います。

## トレンドが示す今後の方向性

本節で紹介したトレンドに共通するのは、「モデル単体ではなく、データとフィードバックループ全体を設計する」という発想です。大規模フリート、世界モデル、自然言語インターフェース、自己教師あり学習、シミュレーション／合成データなどは、それぞれ単独の技術要素であると同時に、Closed-Loop データエンジンを高度化するための部品でもあります。

読者のみなさんには、これらのトレンドを「どの技術が有望か」という視点だけでなく、「自社・自チームのデータエンジンをどのように設計し、どこから段階的に取り入れるか」という視点で捉えていただきたいです。本書の残りの章では、こうしたグローバルトレンドを踏まえつつ、現実的なスケールで実現可能なデータ中心・Closed-Loop 開発の実践方法を詳しく解説していきます。

実務レベルでは、ここで紹介した全てのトレンドを一度に取り入れることは現実的ではありません。そのため、まずは「大規模フリートと DataOps の整備」「シーン検索・Embedding 検索の導入」「Long-tail セットの定義と追跡」といった基盤的な要素から着手し、組織やプロジェクトの成熟度に応じて、世界モデル・自然言語インターフェース・高度なシミュレーション活用へと段階的に拡張していくことが多いです。本書では、各章で「最低限ここから始める」という実務的な導入ステップにも触れながら、グローバルトレンドを現実的なプラクティスへと落とし込んでいきます。

## オープンデータセット・ベンチマークの変遷とデータ中心評価

データ中心な自動運転開発の潮流を理解するうえで、オープンデータセットとベンチマークの進化も重要です。初期の KITTI や Cityscapes から始まり、nuScenes、Waymo Open Dataset、Argoverse、BDD100K など、多数の大規模データセットが公開されてきました。それぞれが異なる ODD・センサー構成・アノテーションポリシーを持っており、「どのようなデータが集められ、どのようなタスクが評価されているか」を比較すること自体が貴重な学びになります。

近年の傾向として、以下のような点が挙げられます。

- **マルチモーダル化**: 画像だけでなく、LiDAR 点群・Radar・マップ情報・車両テレメトリを統合したデータセットが主流になってきています。これにより、Perception だけでなく Prediction / Planning 系タスクの研究も進みました。
- **長時間・シナリオ指向**: 単一フレームのラベルだけでなく、数秒〜数十秒にわたる軌道やシナリオラベル（合流・右折・追い越しなど）を含むデータセットが増えています。
- **ロングテールに対する意識**: 雪道や悪天候、複雑交差点、珍しい車両など、従来のベンチマークでは少なかったシーンを意図的に含める試みも見られます。

ただし、公開データセットはどうしても「研究しやすい ODD」に偏る傾向があり、商用フリートで遭遇するロングテール事象のごく一部しかカバーできていないことが多いです。そのため、データ中心な実務では、公開ベンチマークでのスコアだけに頼るのではなく、自社フリート上での指標（インシデント頻度、介入率、Long-tail セット mAP など）を定義し、それらを Closed-Loop の主指標として扱うことが重要になります。

## ケーススタディ風に見るデータ中心トレンドの組み合わせ

ここまで紹介してきたトレンド（大規模フリート、世界モデル、自然言語インターフェース、自己教師あり学習、シミュレーション／合成データなど）は、現実のプロジェクトでは互いに組み合わされて用いられます。ここでは、匿名化した架空のケーススタディ風に、その組み合わせ方を簡単に描いてみます。

### ケース A: 都市ロボタクシーサービス

ある都市部ロボタクシーサービスでは、以下のような構成でデータ中心開発が行われているとします。

- サービス車両から低レートテレメトリとイベントトリガ付き高解像度ログを収集し、都市別・時間帯別にデータレイクを構築。
- 世界モデル / BEV ベースの統合ネットワークを用い、Perception / Prediction / Planning をマルチタスクで学習。
- オンラインモニタリングにより、交差点右折時のヒヤリハットやドライバ介入を検出し、その周辺ログを Long-tail セットに追加。
- シーン検索基盤により、「雨の夜の交差点右折」シーンを自然言語クエリで抽出し、ラベリングとシミュレーション評価に回す。

このケースでは、世界モデル・フリート DataOps・自然言語検索が一体となって Closed-Loop を形成しており、特定シナリオのリスク低減にフォーカスしたデータ中心改善が継続的に行われていると考えられます。

### ケース B: 量産 ADAS と OTA ベース改善

一方、量産 ADAS の文脈では、次のような構成が想定されます。

- 数十万台規模の量産車両から、匿名化されたテレメトリとイベントトリガログをクラウドに集約。
- オープンデータセットで事前学習したモデルをベースに、自社フリートのデータでファインチューニング。
- OTA により新バージョンモデルを少数の車両から段階的に展開し、オンライン指標と Long-tail セット指標を監視。
- 問題が見つかった場合は、該当バージョン・該当 ODD のデータを再収集・再ラベルし、次のファインチューニングサイクルに投入。

このケースでは、世界モデルや高度なシミュレーションを必ずしもフルに活用していなくても、「フリート × OTA × DataOps」を軸にした Closed-Loop が機能しています。重要なのは、どのレベルの技術を採用しているかではなく、「モデル更新 → モニタリング → データ・ラベル・指標の見直し → 再学習」というループが継続的に回っているかどうかです。

## トレンドを自分たちの文脈に落とし込むために

本節で紹介した各トピックは、それぞれ単独でも深いテーマですが、共通しているのは「モデル単体ではなく、データとフィードバックループ全体を設計する」という発想です。読者のみなさんが自分たちのプロジェクトに適用する際には、次のような観点で優先順位付けを行うとよいと考えられます。

- まず、フリート規模や ODD の広さに対して、現行のデータ収集・保存・検索・ラベリング体制が十分かどうかを評価する。
- そのうえで、「最もボトルネックになっているのはどこか」（例: ログにアクセスするのがとにかく大変、Long-tail シーンを探せない、ラベルポリシーが曖昧、など）を特定する。
- 本節で紹介したトレンドのうち、ボトルネック解消に直結するものから着手する（例: まずはシーン検索 UI の整備、その次に Long-tail セットと世界モデルの導入、など）。

以降の章では、こうした観点を踏まえながら、各フェーズ（データ収集・保存・選択・ラベリング・学習・評価・展開）の具体的な設計・実装方法を掘り下げていきます。本節で俯瞰したグローバルトレンドを頭の片隅に置きつつ、自分たちのプロジェクトにどのように適用できるかを常に意識して読み進めていただければと思います。

また、本節で取り上げたトレンドは、今後数年にわたっても進化し続けると考えられます。世界モデルや Foundation Model のスケール、シミュレーションの写実性、自然言語インターフェースの表現力などは、ハードウェア・アルゴリズム・インフラの進歩とともに急速に変化しています。そのため、「特定の手法やライブラリに依存しすぎず、データと Closed-Loop の設計思想を軸におく」ことが、長期的に見て陳腐化しにくいアーキテクチャを構築するうえで重要になります。

第 2 章以降では、本節で挙げたトレンドを構成要素に持つ具体的なパイプラインやシステムアーキテクチャを取り上げながら、「現実的な制約の中でどこから手を付けるべきか」「どのように段階的に高度化していくか」を掘り下げていきます。
