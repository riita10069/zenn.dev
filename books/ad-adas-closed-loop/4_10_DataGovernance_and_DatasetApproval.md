# 4.10 データガバナンスとデータセット承認プロセス

この節では、データガバナンスとデータセット承認プロセスについて掘り下げます。データガバナンスの主要要素（データ品質チェック、ラインエージ、アクセス制御、コンプライアンス）、承認されたデータセットの管理フロー、センサーやソフトウェアバージョン変更時のデータ移行戦略などを整理し、データ中心・Closed-Loop の観点から「どのデータセットをプロダクションモデルの根拠とするか」を組織的に決め、追跡可能にする仕組みを考えます。

## データガバナンスの構成要素

自動運転のような安全クリティカル領域において、データガバナンスは単なるドキュメントではなく、ツールとワークフローで実現される継続的な守備範囲です。AIMultiple のガイドラインにもあるように、以下の要素を意識する必要があります。

- データ品質：欠損率、分布の逸脱、NULL 値、統計的なドリフトなどを定期的にモニタリングし、品質ゲートにフィードバックします。lakeFS などのデータバージョン制御レイヤーとの組み合わせにより、チェックポイントごとの「品質スナップショット」を保存し、変更がどのデータバージョンで生じたかを追跡できます。
- データラインエージ：データソース、ETL、前処理、ラベリング、評価モデルとの関係をログ・メタデータとして記録し、どのデータがどのモデルに使われたかを追跡します。特にヒヤリハットやインシデントが発生した場合、ラインエージ情報が原因分析と対応策の起点になります。
- データアクセス・コンプライアンス：GDPR/CCPA などの規制に適合したアクセス制御、暗号化、監査ログを整備し、個人情報や機密データの取り扱いを明確化します。
- データバージョニング：DVC や lakeFS などを使ってデータセットのスナップショットを管理し、ロールバック・比較を可能にします。特に DVC のように Git と連携する方式は、モデル・パイプライン・データを同期的にバージョニングする観点で有用です。

これらの要素は、データ品質テスト・CI/CD の一部としてワークフローオーケストレータから実行され、ゲートが合格しないデータは次の工程に進めない仕組みが望ましいです。

## データセットレビュー・承認フロー

承認プロセスでは、単なる技術的レビューに留まらず、セーフティチーム・法務・運用・データエンジニアリングが集まる「データ評価委員会」を設け、以下の観点を定期的に確認します。

- データセットのカバレッジ：ODD セグメント別、シナリオ別、クラス別のサンプル数・性能指標のヒートマップを提示し、データの網羅性と偏りを可視化する。
- 品質指標：前処理バージョン、匿名化手法、タイムスタンプ整合性、センサー稼働率などの品質メトリクスのパス/フェイルを確認する。
- ガバナンス遵守状況：アクセスログの記録、データ匿名化の適用状況、コンプライアンスレビュー（GDPR/CCPA など）を精査する。
- ラインエージとデータ依存：どのモデル実験がそのデータセットバージョンを使ったか、どのラベルポリシーや前処理バージョンと結合されたかを追跡し、必要に応じて再評価する。

承認済みのデータセットバージョンのみを本番向けモデル学習・評価に使うポリシーを定め、承認の証跡（承認日・承認者・レビューコメント）をデータカタログや MLOps メタデータストアに記録します。各データセットバージョンにはメタフィールド（スキーマバージョン、前処理バージョン、匿名化レベル、スプリット定義など）を持たせることで、後から参照しやすくなります。

## センサー／ソフトウェアバージョン変更時の移行戦略

センサー構成や車載ソフトウェアのバージョンが変わると、データ分布、キャリブレーション、ラベル解釈が変化する可能性があるため、Closed-Loop の観点では適切な移行戦略が不可欠です。

1. **バージョンタグ付け**：収集データには取得時のセンサー構成、キャリブレーションパラメータ、車両ソフトウェアバージョン、OS/ドライババージョンを含むタグを付加し、クエリ可能にします。これにより、特定バージョンのデータのみを抽出してスプリットを作成できます。
2. **データバージョン分離**：バージョンアップ前後のデータを明確に区切り、必要ならば異なる学習・評価セットとして管理します。旧バージョンと新バージョンを併用する場合、モデルに与えるバイアスを分析するための定量的な比較が不可欠です。
3. **品質ゲートの再評価**：新バージョンに対しては上記の品質ゲートを再実行し、ラインエージと比較することで品質劣化や分布シフトを検出します。異常な drift が検出された場合は、収集パラメータ・キャリブレーション設定・センサ校正の見直しをフィードバックループとして回します。
4. **差分分析と統合基準**：例えば、センサー感度が向上したことで特定クラスの検出数が急増した場合、旧バージョンとの比較や再ラベリングを行い、ラベル整合性を保ちながら新旧データの統合基準（重み付けやドメインアダプテーション）を定めます。

## データガバナンスのモニタリングとフィードバック

データガバナンスには監査合格の他に、「継続的改善」が求められます。具体的には、

- データ品質チェックの失敗件数・失敗分布をダッシュボードで追跡し、頻発する品質課題を改善バックログに落とす。
- 承認済みデータセットバージョンの使用履歴を追跡し、実運用モデルとの適合性を監視する。
- ヒヤリハット・インシデント・異常検出結果をデータ品質・ラインエージと紐づけ、根本原因分析 (RCA) に活用する。
- 変更履歴 (preprocess version, schema version, governance policies) を CI/CD でトレースし、変更がモデル性能に与える影響を実験管理ツールで評価する。

このような取り組みにより、データ中心・Closed-Loop のプロセスの中で、「どのデータが安全な判断を支えるのか」を透明にし、規制対応や安全レビューにも耐えうるエビデンスを提供することができます。
