---
title: "4.2 データクレンジングと品質ゲート"
---

# 4.2 データクレンジングと品質ゲート

この節では、データクレンジング (data cleansing) と品質ゲート (quality gate) の設計について解説します。センサー故障・露出異常・タイムスタンプ不整合の検出、ドライバ行動の異常・計測バグの切り分け、データパイプラインにおける自動チェックの仕組みなどを整理し、データ中心・Closed-Loop の観点から「学習・評価に使うべきでないデータ」を早期に排除する重要性を説明します。ここでいう品質ゲートは、CI/CD におけるテストゲートと同様に、データが次の工程に進む前に所定の品質条件を満たしているかどうかを機械的に判定する仕組みを指します。

## センサー故障・露出異常・タイムスタンプ不整合の検出

第 2 章・第 3 章で扱ったオンボードモニタリングや時刻同期情報を活用し、学習・評価用データセットを構築する前に品質チェックを行います。

- カメラ画像の露出異常（ほぼ真っ黒・真っ白）や極端なブラーを検出する。
- LiDAR / Radar の有効点数や反射強度の統計から異常フレームを検出する。
- タイムスタンプ不整合（逆行、重複、ドリフト）を検出し、補正または除外を行う。

これらのチェックは、ルールベースとモデルベース（異常検知モデル）を組み合わせて行うことが多いです。ルールベースの例としては、

- 露光時間・ゲイン・シャッタースピードのメタデータに対するしきい値チェック。
- LiDAR のポイント数や有効レンジに対する範囲チェック。
- GPS / IMU のステータスフラグ（fix 状態・精度指標）の検査。

などが挙げられます。モデルベースでは、自己教師あり学習 (self-supervised learning) によって「正常な走行シーン」の表現を学習し、再構成誤差やマスク予測誤差の大きさを異常スコアとして用いる手法や、セマンティックセグメンテーション出力に対する異常スコアリング（未知クラス検出）などが研究・実務の両面で広がりつつあります。

## ドライバ行動の異常・計測バグの切り分け

データ中に現れる異常挙動が、「現実の危険運転」なのか「計測系のバグ」なのかを切り分けることも重要です。例えば、急ブレーキや急ハンドルが頻発している場合、それがドライバの運転スタイルなのか、センサーの誤検出や制御バグなのかを区別する必要があります。

- 車両 CAN / ECU から取得した制御コマンドと、実際の車両挙動（速度・加速度・ヨーレート）との整合性を確認する。
- Onboard ADAS / AD のログ（AEB 介入、LKA 介入など）と、センサデータのタイムラインを突き合わせる。
- 異常イベントが特定車両・特定センサ・特定ソフトウェアバージョンに偏っていないかを統計的に分析する。

この切り分けは、単に「悪いデータを捨てる」ためだけでなく、センサーや制御ソフトウェア側の不具合を早期に検知し、Closed-Loop で改善につなげるためにも重要です。異常なシグナルが特定の車両やロットに集中している場合は、ハードウェア・キャリブレーション・インストール状態などを点検するトリガとします。

## データクレンジング処理の具体例

データクレンジングでは、「除外」「補正」「タグ付け」の 3 種類のアクションを組み合わせることが多いです。

- 除外：学習・評価に用いるべきでないフレームやシーンを完全に除外する（例: センサオフライン、露出完全に飽和、タイムスタンプが壊れているなど）。
- 補正：軽微な異常（タイムスタンプのわずかなズレ、欠損値のスパースな発生など）については補間・再サンプリングで補正する。
- タグ付け：異常だが学習には有用なケース（センサの一時的な遮蔽、トンネルの出入りでの露出変化など）は、「データ品質タグ」を付けて後段で利用可否を選べるようにする。

例えば、タイムスタンプのドリフトについては、同期信号（PTP / GPS 時刻）を基準にオフセット推定を行い、一定範囲内であれば補正、それを超える場合はシーン単位で除外するといったポリシーを取ることが考えられます。

## 品質ゲートの設計と自動化

品質ゲートは、データパイプラインの各段階で実行される自動チェック群です。ソフトウェア開発におけるテストゲートと同様に、「ゲートを通過したデータのみが次の工程（ラベリング・学習・評価）に進める」というルールを明確にします。

データパイプラインでは、例えば次のような層別の品質ゲートを設計できます。

- インジェスト直後のゲート：ファイルフォーマット（ROS bag, Parquet, WebDataset 等）の整合性、必須チャネルの有無、メタデータの存在をチェックする。
- 前処理後のゲート：匿名化処理の実施有無、解像度・フレームレート・センサキャリブレーションの一貫性を確認する。
- ラベリング前後のゲート：ラベルスキーマに従った値のみが使われているか、クラス ID の欠損や不整合がないかを検査する。

これらの品質ゲートは、単発のスクリプトではなく「再利用可能なチェック」として定義しておくと管理しやすいです。一般的なデータ品質フレームワークでは、

- スキーマ検証（カラムの存在・型・許容値の範囲）。
- 統計的検証（NULL 率、ユニーク制約、分布の逸脱）。
- 関係検証（外部キー整合性、クロスフィールド制約）。

といったチェックを宣言的に記述し、バッチやストリームに対して一括実行する機能が提供されています。自動運転データの場合は、これに加えて「時系列・センサ同期・空間的整合性（センサフュージョン時の投影整合）」に関するチェックを独自に追加することが多いです。

## データ品質ツールとワークフロー連携

データ品質チェックを人手だけで回すのは現実的ではないため、実務では以下のようなツール群が利用されます。

- データバリデーション・フレームワーク：スキーマ検証や統計的検証を宣言的に定義できるツール群（例: Python ベースの検証フレームワークや、SQL テンプレートを用いた検証ツールなど）。
- 分散処理基盤との統合：Spark / Flink / Beam 等の分散処理フレームワーク上で、データ品質チェックをジョブの一部として実行する仕組み。
- ワークフローオーケストレータとの連携：Airflow, Dagster, Prefect 等のワークフローツールから品質ゲートをタスクとして呼び出し、失敗時に後続タスクを停止する。

特定のツールに依存しない設計とするため、品質ルールは YAML や JSON、あるいは Python / SQL のコードとしてリポジトリに保存し、CI 上でテスト・レビューできるようにすることが望ましいです。これにより、「どの時点でどの品質チェックが実行されているか」を監査可能にしつつ、将来的なツール乗り換えにも対応しやすくなります。

## Closed-Loop における品質ゲートの役割

Closed-Loop の観点では、品質ゲートは単に「悪いデータを弾くフィルタ」ではなく、「品質インシデントを検知し、データ収集・センサ・ソフトウェア開発にフィードバックを返すためのセンサー」として機能します。

- 品質ゲートで検出された異常を、センサベンダー・ハードウェアチーム・フリート運用チームと共有し、再発防止策を検討する。
- データクレンジングで除外したシーンを、別のバケット（「品質問題調査用」データセット）として保存し、根本原因分析 (RCA) に活用する。
- 品質ゲートのルールやしきい値を、実運用からのフィードバックに基づいて継続的に調整し、過剰除外や過少除外を防ぐ。

このように、データクレンジングと品質ゲートを一体として設計し、データレイク／MLOps 基盤に組み込むことで、学習・評価データセットの健全性を保ちつつ、長期的なフリート運用とセンサ・ソフトウェアの成熟を支えることができます。

